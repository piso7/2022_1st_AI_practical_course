{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3주차(금)_CNN실습(공유)_김민솔.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 0. 데이터 불러오기\n",
        "https://drive.google.com/file/d/1M8KwdmGm8EWCn_IEWAcctbUJBww-M3cF/view?usp=sharing\n",
        "\n",
        "1. 위 링크에 있는 zip 파일을 '드라이브에 바로가기 추가'하기(안되면 그냥 다운로드 후 내 드라이브에 업로드)\n",
        "2. GPU 설정 후, 드라이브 마운트\n",
        "3. zip 파일 풀기 (약 2분 소요)"
      ],
      "metadata": {
        "id": "TDekbT7bHvKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rD68wg6GRaeQ",
        "outputId": "2530c040-833d-40a7-c91f-88b9745b01e6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip -uq “압축을 풀 zip 파일의 경로” -d “압축을 풀고자 하는 폴더의 경로”\n",
        "!unzip -uq /content/drive/MyDrive/plant-leaf-dataset.zip -d /content/drive/MyDrive/plant-leaf-dataset"
      ],
      "metadata": {
        "id": "0CrELDhBI3yO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAmOFLpdtXV5"
      },
      "source": [
        "### 1. 데이터 분할을 위한 디렉토리 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH7lRtSlpG7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "d52c9825-6b36-45c2-8f5c-313e402ea1a2"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "original_dataset_dir = '/content/drive/MyDrive/plant-leaf-dataset/plant-leaf-dataset' #데이터셋이 위치한 경로 지정  \n",
        "classes_list = os.listdir(original_dataset_dir) #해당 경로 하위에 있는 모든 폴더의 목록을 가져옴(폴더 목록 == 클래스 목록)\n",
        " \n",
        "base_dir = '/content/drive/MyDrive/plant-leaf-dataset/plant-leaf-new-dataset' #train/val/test로 분할한 데이터를 저장할 폴더 생성\n",
        "os.mkdir(base_dir)\n",
        " \n",
        "train_dir = os.path.join(base_dir, 'train') #train 폴더 생성\n",
        "os.mkdir(train_dir)\n",
        "validation_dir = os.path.join(base_dir, 'val') #\bvalidation 폴더 생성\n",
        "os.mkdir(validation_dir)\n",
        "test_dir = os.path.join(base_dir, 'test') #test 폴더 생성\n",
        "os.mkdir(test_dir)\n",
        "\n",
        "for cls in classes_list: #train/val/test 폴더에 각각 클래스 목록 폴더를 생성    \n",
        "    os.mkdir(os.path.join(train_dir, cls))\n",
        "    os.mkdir(os.path.join(validation_dir, cls))\n",
        "    os.mkdir(os.path.join(test_dir, cls))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-ff68ca51ce98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mbase_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/plant-leaf-dataset/plant-leaf-new-dataset'\u001b[0m \u001b[0;31m#train/val/test로 분할한 데이터를 저장할 폴더 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtrain_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#train 폴더 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/content/drive/MyDrive/plant-leaf-dataset/plant-leaf-new-dataset'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. train/validation/test 데이터 분할 및 클래스 별 데이터 수 확인"
      ],
      "metadata": {
        "id": "eKJ1QY2e28i4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_v0a0PUSrdnZ",
        "outputId": "95cc46ad-eabb-4620-fa11-c4c81afe0bec"
      },
      "source": [
        "import math\n",
        "for cls in classes_list: #모든 클래스에 대한 작업 반복\n",
        "    path = os.path.join(original_dataset_dir, cls) \n",
        "    fnames = os.listdir(path) #path 위치에 존재하는 모든 이미지 파일의 목록을 fnames에 저장\n",
        "    \n",
        "    #train/validation/test 의 비율을 6:2:2로 (데이터 규모에 따라 조정 가능)\n",
        "    train_size = math.floor(len(fnames) * 0.6)\n",
        "    validation_size = math.floor(len(fnames) * 0.2)\n",
        "    test_size = math.floor(len(fnames) * 0.2)\n",
        "    \n",
        "    #train\n",
        "    train_fnames = fnames[:train_size] #train 데이터에 해당하는 파일의 이름을 train_fnames에 저장\n",
        "    for fname in train_fnames: #train 데이터에 대해 for문의 내용 반복\n",
        "        src = os.path.join(path, fname) #복사할 원본 파일의 경로 지정\n",
        "        dst = os.path.join(os.path.join(train_dir, cls), fname) #복사한 후 저장할 파일의 경로 지정\n",
        "        shutil.copyfile(src, dst) #src의 경로에 해당하는 파일을 dst의 경로에 지정\n",
        "    \n",
        "    #validation\n",
        "    validation_fnames = fnames[train_size:(validation_size + train_size)]\n",
        "    for fname in validation_fnames:\n",
        "        src = os.path.join(path, fname)\n",
        "        dst = os.path.join(os.path.join(validation_dir, cls), fname)\n",
        "        shutil.copyfile(src, dst)\n",
        "        \n",
        "    #test    \n",
        "    test_fnames = fnames[(train_size + validation_size):(test_size + validation_size + train_size)]\n",
        "    for fname in test_fnames:\n",
        "        src = os.path.join(path, fname)\n",
        "        dst = os.path.join(os.path.join(test_dir, cls), fname)\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "    print(\"class(\",cls,\") Train:\",len(train_fnames), \"Validation:\",len(validation_fnames), \"Test:\",len(test_fnames))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class( Apple___healthy ) Train: 987 Validation: 329 Test: 329\n",
            "class( Grape___healthy ) Train: 253 Validation: 84 Test: 84\n",
            "class( Grape___Black_rot ) Train: 708 Validation: 236 Test: 236\n",
            "class( Peach___Bacterial_spot ) Train: 1378 Validation: 459 Test: 459\n",
            "class( Potato___healthy ) Train: 91 Validation: 30 Test: 30\n",
            "class( Potato___Early_blight ) Train: 600 Validation: 200 Test: 200\n",
            "class( Corn___Common_rust ) Train: 715 Validation: 238 Test: 238\n",
            "class( Strawberry___Leaf_scorch ) Train: 671 Validation: 223 Test: 223\n",
            "class( Apple___Apple_scab ) Train: 378 Validation: 126 Test: 126\n",
            "class( Strawberry___healthy ) Train: 273 Validation: 91 Test: 91\n",
            "class( Peach___healthy ) Train: 216 Validation: 72 Test: 72\n",
            "class( Corn___healthy ) Train: 697 Validation: 232 Test: 232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYCY0sqFso7L"
      },
      "source": [
        "### 3. 기본 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucURIVBmsnmC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6638aa85-29e3-400b-eebd-f1a522c0487b"
      },
      "source": [
        "import torch\n",
        "import os\n",
        " \n",
        "USE_CUDA = torch.cuda.is_available() #GPU 사용 가능한지 확인하는 메서드(사용할 수 있으면 TRUE, 없으면 FALSE 반환)\n",
        "print(USE_CUDA)\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\") #DEVICE 변수에 TRUE 이면 cuda를 FALSE 이면 cpu를 저장\n",
        "print(DEVICE)\n",
        "\n",
        "BATCH_SIZE = 512 #배치사이즈 지정\n",
        "EPOCH = 5 #에포크 지정\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "data_transforms = { # transforms.Compose()는 이미지 전처리, Augmentation 등 사용, Augmentation이란? 좌우 반전, 밝기 조절, 이미지 확대 등 노이즈를 주어 더 강한 모델을 만들어 주는 기법\n",
        "    'train': transforms.Compose([transforms.Resize([64,64]), # Resize -> 이미지의 크기를 64x64로 조정                    \n",
        "                                 transforms.RandomHorizontalFlip(), #RandomHorizontalFlip -> 이미지를 무작위로 좌우 반전\n",
        "                                 transforms.RandomVerticalFlip(), #RandomVerticalFlip -> 이미지를 무작위로 상하 반전\n",
        "                                 transforms.RandomCrop(52), #RandomCrop -> 이미지의 일부를 랜덤하게 잘라서 52x52 사이즈로 변경\n",
        "                                 transforms.ToTensor(), # ToTensor -> 이미지를 텐서 형태로 변환하고, 모든 값을 0~1 사이로 변경\n",
        "                                 transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ]), #Normalize ->정규화를 위해선 평균값과 표준편차값이 필요\n",
        "                                                                                                        #            첫번째[]는 R,G,B 채널 값에서 정규화를 적용할 평균값 \n",
        "                                                                                                        #            두번째[]는 R,G,B 채널 값에서 정규화를 적용할 표준편차값 \n",
        "                                                                                                        #            이 값은 이미지넷 데이터의 값이고, 정규화는 Local Minimum에 빠지는 것을 방지\n",
        "    'val': transforms.Compose([transforms.Resize([64,64]), \n",
        "                               #validation data는 Augmentation에 해당하는 부분을 제외하고 동일하게 전처리 \n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ])\n",
        "}"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. 데이터 로더"
      ],
      "metadata": {
        "id": "e0zmtPpS9oAW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STs5oRi2sy12",
        "outputId": "6f3d41f5-90fe-4d9c-86c7-71763af49ac2"
      },
      "source": [
        "from torchvision.datasets import ImageFolder #이미지 데이터는 하나의 클래스가 하나의 폴더에 대응되기 때문에 데이터셋을 불러올 때 ImageFolder를 사용\n",
        "\n",
        "# ImageFolder로 데이터셋 불러오기 -> root : 데이터 불러 올 경로 설정, transform : 앞서 설정한 전처리 방법 지정(불러오기 편하게 딕셔너리 형태로 구성)\n",
        "image_datasets = {x: ImageFolder(root=os.path.join(base_dir, x), transform=data_transforms[x]) for x in ['train', 'val']} \n",
        "\n",
        "# DataLoader로 불러온 이미지 데이터를 주어진 조건에 따라 미니 배치 단위로 분리 -> shuffle=True : 데이터의 순서가 섞여 학습시에 Label 정보의 순서를 기억하는 것을 방지 할 수 있음 필수!\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=4) for x in ['train', 'val']} \n",
        "\n",
        "#train/validation의 총 개수를 저장\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "\n",
        "#12개 클래스의 목록을 저장\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "print(class_names)\n",
        "print(len(class_names))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Apple___Apple_scab', 'Apple___healthy', 'Corn___Common_rust', 'Corn___healthy', 'Grape___Black_rot', 'Grape___healthy', 'Peach___Bacterial_spot', 'Peach___healthy', 'Potato___Early_blight', 'Potato___healthy', 'Strawberry___Leaf_scorch', 'Strawberry___healthy']\n",
            "12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. 전이학습 모델 불러오기\n",
        "1. 모델만 불러와서 구조 print 해보기\n",
        "2. 분류층 바꾸고 print 해보기"
      ],
      "metadata": {
        "id": "Uy5j3kc79q6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcyG2cKePI5L",
        "outputId": "ff10c42d-e262-4fd2-b234-7a56470fc661"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet_pytorch) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (3.10.0.2)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=faf00f27a31cb9fb84557f03c96c0485366cf3c9d96b041c174268d9e739f43a\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/cc/b2/49e74588263573ff778da58cc99b9c6349b496636a7e165be6\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZEFZgmTs2Vt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abdcb08a-df6e-4411-ee5b-0ec35273f2bc"
      },
      "source": [
        "from torchvision import models #pytorch 공식문서에서 확인 한 것처럼, 여기서 여러 모델을 불러올 수 있음\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "'''\n",
        "#resnet18/34/50 \n",
        "model = models.resnet50(pretrained=True) #pretrained=True로 설정하면 pre-trained model의 parameter값을 그대로 가져옴, False로 설정하면 모델의 아키텍처만 가져오고 parameter는 랜덤 설정\n",
        "num_ftrs = model.fc.in_features #모델의 마지막 레이어의 입력 채널의 수를 저장(in_features는 해당 레이어의 입력 채널 수를 의미)   \n",
        "model.fc = nn.Linear(num_ftrs, len(class_names)) #모델의 마지막 레이어를 새로운 레이어로 교체 (입력 채널 수는 기존 레이어와 동일, 출력 채널 수를 우리가 원하는 수로 설정하는 것! 여기서는 클래스 수 12개) \n",
        "\n",
        "\n",
        "#vgg16/19\n",
        "model = models.vgg16(pretrained=True)\n",
        "model.classifier[6].out_features = len(class_names) #마지막 레이어를 교체하는 방법이 약간 다름, print 해서 구조 확인하면서 이해\n",
        "\n",
        "#mobilenet_v2\n",
        "model = models.mobilenet_v2(pretrained=True)\n",
        "#model.classifier[1].out_features = len(class_names)\n",
        "\n",
        "#mobilnet_v3_small\n",
        "model = models.mobilenet_v3_small(pretrained=True)\n",
        "#model.classifier[3].out_features = len(class_names)\n",
        "\n",
        "#googlenet\n",
        "model = models.googlenet(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, len(class_names))\n",
        "\n",
        "'''\n",
        "#efficientnet_b0\n",
        "model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=12)\n",
        "\n",
        "\n",
        "model = model.to(DEVICE) #모델 gpu에 태우기\n",
        "print(model)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b0\n",
            "EfficientNet(\n",
            "  (_conv_stem): Conv2dStaticSamePadding(\n",
            "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
            "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
            "  )\n",
            "  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "  (_blocks): ModuleList(\n",
            "    (0): MBConvBlock(\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (1): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (2): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (3): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (4): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (5): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (6): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (7): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (8): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (9): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (10): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (11): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (12): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (13): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (14): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (15): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "  )\n",
            "  (_conv_head): Conv2dStaticSamePadding(\n",
            "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "    (static_padding): Identity()\n",
            "  )\n",
            "  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
            "  (_dropout): Dropout(p=0.2, inplace=False)\n",
            "  (_fc): Linear(in_features=1280, out_features=12, bias=True)\n",
            "  (_swish): MemoryEfficientSwish()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Layer Freeze"
      ],
      "metadata": {
        "id": "4zzyFflRf13T"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wf8IIPgs3vs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a61c5def-034e-4e45-a613-0870004d1d28"
      },
      "source": [
        "cnt = 0 #몇 번째 Layer인지 나타내는 변수 cnt 설정\n",
        "\n",
        "for child in model.children(): #모델의 모든 Layer 정보를 담고 있음 (vgg, mobilenet 계열은 model.features)\n",
        "    cnt += 1 \n",
        "    #import pdb;pdb.set_trace() #디버거 cnt,n,c,child,q\n",
        "    if cnt < 4: #resnet50기준 10개의 Layer중 1~5개는 Freeze하고, 6~10은 학습 시 parameter를 업데이트 하도록!\n",
        "        print(child)\n",
        "        for param in child.parameters(): #vgg, mobilenet 계열은 model.features.parameters()\n",
        "            param.requires_grad = False  #False -> NO UPDATE(FREEZE), True -> UPDATE(기본값)\n"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv2dStaticSamePadding(\n",
            "  3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
            "  (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
            ")\n",
            "BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "ModuleList(\n",
            "  (0): MBConvBlock(\n",
            "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "      32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
            "      (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "    )\n",
            "    (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_se_reduce): Conv2dStaticSamePadding(\n",
            "      32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_se_expand): Conv2dStaticSamePadding(\n",
            "      8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_project_conv): Conv2dStaticSamePadding(\n",
            "      32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_swish): MemoryEfficientSwish()\n",
            "  )\n",
            "  (1): MBConvBlock(\n",
            "    (_expand_conv): Conv2dStaticSamePadding(\n",
            "      16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "      96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
            "      (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
            "    )\n",
            "    (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_se_reduce): Conv2dStaticSamePadding(\n",
            "      96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_se_expand): Conv2dStaticSamePadding(\n",
            "      4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_project_conv): Conv2dStaticSamePadding(\n",
            "      96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_swish): MemoryEfficientSwish()\n",
            "  )\n",
            "  (2): MBConvBlock(\n",
            "    (_expand_conv): Conv2dStaticSamePadding(\n",
            "      24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "      144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
            "      (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "    )\n",
            "    (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_se_reduce): Conv2dStaticSamePadding(\n",
            "      144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_se_expand): Conv2dStaticSamePadding(\n",
            "      6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_project_conv): Conv2dStaticSamePadding(\n",
            "      144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_swish): MemoryEfficientSwish()\n",
            "  )\n",
            "  (3): MBConvBlock(\n",
            "    (_expand_conv): Conv2dStaticSamePadding(\n",
            "      24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "      144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
            "      (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
            "    )\n",
            "    (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_se_reduce): Conv2dStaticSamePadding(\n",
            "      144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_se_expand): Conv2dStaticSamePadding(\n",
            "      6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_project_conv): Conv2dStaticSamePadding(\n",
            "      144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_swish): MemoryEfficientSwish()\n",
            "  )\n",
            "  (4): MBConvBlock(\n",
            "    (_expand_conv): Conv2dStaticSamePadding(\n",
            "      40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "      240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
            "      (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "    )\n",
            "    (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_se_reduce): Conv2dStaticSamePadding(\n",
            "      240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_se_expand): Conv2dStaticSamePadding(\n",
            "      10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_project_conv): Conv2dStaticSamePadding(\n",
            "      240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_swish): MemoryEfficientSwish()\n",
            "  )\n",
            "  (5): MBConvBlock(\n",
            "    (_expand_conv): Conv2dStaticSamePadding(\n",
            "      40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "      240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
            "      (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
            "    )\n",
            "    (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_se_reduce): Conv2dStaticSamePadding(\n",
            "      240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_se_expand): Conv2dStaticSamePadding(\n",
            "      10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_project_conv): Conv2dStaticSamePadding(\n",
            "      240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_swish): MemoryEfficientSwish()\n",
            "  )\n",
            "  (6): MBConvBlock(\n",
            "    (_expand_conv): Conv2dStaticSamePadding(\n",
            "      80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "      480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
            "      (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "    )\n",
            "    (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_se_reduce): Conv2dStaticSamePadding(\n",
            "      480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_se_expand): Conv2dStaticSamePadding(\n",
            "      20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_project_conv): Conv2dStaticSamePadding(\n",
            "      480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_swish): MemoryEfficientSwish()\n",
            "  )\n",
            "  (7): MBConvBlock(\n",
            "    (_expand_conv): Conv2dStaticSamePadding(\n",
            "      80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "      480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
            "      (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "    )\n",
            "    (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_se_reduce): Conv2dStaticSamePadding(\n",
            "      480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_se_expand): Conv2dStaticSamePadding(\n",
            "      20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_project_conv): Conv2dStaticSamePadding(\n",
            "      480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_swish): MemoryEfficientSwish()\n",
            "  )\n",
            "  (8): MBConvBlock(\n",
            "    (_expand_conv): Conv2dStaticSamePadding(\n",
            "      80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "      480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
            "      (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "    )\n",
            "    (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_se_reduce): Conv2dStaticSamePadding(\n",
            "      480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_se_expand): Conv2dStaticSamePadding(\n",
            "      20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_project_conv): Conv2dStaticSamePadding(\n",
            "      480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_swish): MemoryEfficientSwish()\n",
            "  )\n",
            "  (9): MBConvBlock(\n",
            "    (_expand_conv): Conv2dStaticSamePadding(\n",
            "      112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "      672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
            "      (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "    )\n",
            "    (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_se_reduce): Conv2dStaticSamePadding(\n",
            "      672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_se_expand): Conv2dStaticSamePadding(\n",
            "      28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_project_conv): Conv2dStaticSamePadding(\n",
            "      672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_swish): MemoryEfficientSwish()\n",
            "  )\n",
            "  (10): MBConvBlock(\n",
            "    (_expand_conv): Conv2dStaticSamePadding(\n",
            "      112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "      672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
            "      (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "    )\n",
            "    (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_se_reduce): Conv2dStaticSamePadding(\n",
            "      672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_se_expand): Conv2dStaticSamePadding(\n",
            "      28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_project_conv): Conv2dStaticSamePadding(\n",
            "      672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_swish): MemoryEfficientSwish()\n",
            "  )\n",
            "  (11): MBConvBlock(\n",
            "    (_expand_conv): Conv2dStaticSamePadding(\n",
            "      112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "      672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
            "      (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
            "    )\n",
            "    (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_se_reduce): Conv2dStaticSamePadding(\n",
            "      672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_se_expand): Conv2dStaticSamePadding(\n",
            "      28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_project_conv): Conv2dStaticSamePadding(\n",
            "      672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_swish): MemoryEfficientSwish()\n",
            "  )\n",
            "  (12): MBConvBlock(\n",
            "    (_expand_conv): Conv2dStaticSamePadding(\n",
            "      192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "      1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
            "      (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "    )\n",
            "    (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_se_reduce): Conv2dStaticSamePadding(\n",
            "      1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_se_expand): Conv2dStaticSamePadding(\n",
            "      48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_project_conv): Conv2dStaticSamePadding(\n",
            "      1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_swish): MemoryEfficientSwish()\n",
            "  )\n",
            "  (13): MBConvBlock(\n",
            "    (_expand_conv): Conv2dStaticSamePadding(\n",
            "      192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "      1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
            "      (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "    )\n",
            "    (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_se_reduce): Conv2dStaticSamePadding(\n",
            "      1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_se_expand): Conv2dStaticSamePadding(\n",
            "      48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_project_conv): Conv2dStaticSamePadding(\n",
            "      1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_swish): MemoryEfficientSwish()\n",
            "  )\n",
            "  (14): MBConvBlock(\n",
            "    (_expand_conv): Conv2dStaticSamePadding(\n",
            "      192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "      1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
            "      (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "    )\n",
            "    (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_se_reduce): Conv2dStaticSamePadding(\n",
            "      1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_se_expand): Conv2dStaticSamePadding(\n",
            "      48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_project_conv): Conv2dStaticSamePadding(\n",
            "      1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_swish): MemoryEfficientSwish()\n",
            "  )\n",
            "  (15): MBConvBlock(\n",
            "    (_expand_conv): Conv2dStaticSamePadding(\n",
            "      192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "      1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
            "      (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "    )\n",
            "    (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_se_reduce): Conv2dStaticSamePadding(\n",
            "      1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_se_expand): Conv2dStaticSamePadding(\n",
            "      48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_project_conv): Conv2dStaticSamePadding(\n",
            "      1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (static_padding): Identity()\n",
            "    )\n",
            "    (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "    (_swish): MemoryEfficientSwish()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. 손실함수, 최적화함수, 스케쥴러 설정\n",
        "- Adam vs SGD\n",
        "- learning rate는 작게!\n",
        "- 미리 학습 코드까지 실행!"
      ],
      "metadata": {
        "id": "onKCFqbZf9oZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 학습에 사용하는 Loss 함수를 지정\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#Optimizer는 Adam, filter와 lambda를 사용하는 이유 : param.requires_grad = True로 설정된 Layer의 parameter만을 업데이트 하기 위해서!\n",
        "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0005) #전이학습 시에는 lr 낮게(과적합 방지)\n",
        " \n",
        "from torch.optim import lr_scheduler\n",
        "# 에포크에 따라 Learning Rate를 변경하는 역할 (7 에포크마다 0.1씩 곱해 LR을 감소시킴), Why? : 학습 보폭을 정하는 일은 매우 중요한데, 처음엔 크게 -> 학습 진행될 수록 작게 설정하는 것이 좋다고 알려짐, but 아직 연구중\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "LfwDUXcaD_uD"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. 모델 학습 및 저장"
      ],
      "metadata": {
        "id": "t86IqtKnK8Qr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXFjVMs3s5Jv"
      },
      "source": [
        "# 전이학습 모델 학습 및 검증\n",
        "import time\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n",
        "    \n",
        "    train_losses , train_accuracy = [],[] #그래프 그리기 위해서 train에 대한 loss,accuracy 저장\n",
        "    val_losses , val_accuracy = [],[] #그래프 그리기 위해서 validation에 대한 loss,accuracy 저장\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())  #정확도가 가장 높은 모델을 저장\n",
        "    best_acc = 0.0 #정확도가 가장 높은 모델의 정확도 저장\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print('-------------- epoch {} ----------------'.format(epoch+1)) \n",
        "        since = time.time() #한 에포크 돌 때 소요되는 시간 측정(시작 시각 저장)                                    \n",
        "        for phase in ['train', 'val']: #한 에포크 돌 때 train 한 번, validation 한 번씩 각각 진행\n",
        "            if phase == 'train': \n",
        "                model.train() #train이면 학습 모드\n",
        "            else:\n",
        "                model.eval() #validation이면 평가 모드(평가 때 사용하지 말아야 할 작업들 알아서 꺼줌, dropout이나 batchnorm layer 같은 것들)     \n",
        " \n",
        "            running_loss = 0.0   #모든 데이터의 loss를 합해서 저장\n",
        "            running_corrects = 0 #정확하게 예측한 경우의 수를 저장\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]: #모델의 현재 모드(train or validation)에 해당하는 Dataloader에서 데이터를 받는 for문\n",
        "                inputs = inputs.to(DEVICE) #데이터를 gpu에 태움 \n",
        "                labels = labels.to(DEVICE) #데이터의 라벨값을 gpu에 태움\n",
        "                \n",
        "                optimizer.zero_grad() #학습 진행하면 이전 Batch의 Gradient값이 Optimizer에 저장될 것이므로 초기화 해주고 시작해야 함\n",
        "                \n",
        "                with torch.set_grad_enabled(phase == 'train'): #set_grad_enabled를 이용하면 train 모드에서만 모델의 Gradient를 업데이트 하도록 설정 할 수 있음\n",
        "                    outputs = model(inputs) #드디어 데이터를 모델에 입력!\n",
        "                    _, preds = torch.max(outputs, 1) #모델에 입력된 데이터가 12개의 클래스에 속할 확률값 출력, 이 중 가장 높은 값의 인덱스를 예측값으로 preds에 저장\n",
        "                    loss = criterion(outputs, labels) #모델의 예측값과 정답값 사이의 Loss를 계산(criterion 함수는 위에서 미리 설정해 둔 것)\n",
        "    \n",
        "                    if phase == 'train':   \n",
        "                        loss.backward() #계산한 loss값을 이용하여 BackPropagation을 통해 계산한 Gradient값을 parameter에 할당하고,\n",
        "                        optimizer.step() #모델의 parameter 업데이트\n",
        " \n",
        "                running_loss += loss.item() * inputs.size(0) #모든 데이터의 loss를 합해서 저장하기 위해, 하나의 미니 배치에 대한 loss값에 데이터의 수를 곱해서 더함 (inputs.size(0)이 미니 배치의 수) \n",
        "                running_corrects += torch.sum(preds == labels.data) #예측값과 정답값이 같으면 증가!\n",
        "\n",
        "            if phase == 'train':  \n",
        "                scheduler.step() #위에서 미리 설정한 Scheduler 실행\n",
        " \n",
        "            epoch_loss = running_loss/dataset_sizes[phase] #해당 에포크의 loss를 계산하기 위해 running_loss를 데이터셋 사이즈로 나눔\n",
        "            epoch_acc = running_corrects.double()/dataset_sizes[phase] #정확도도 마찬가지로 running_corrects를 데이터셋 사이즈로 나눔\n",
        " \n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc)) #해당 에포크의 loss와 정확도를 매번 출력\n",
        "\n",
        "            if phase == 'train': #그래프 그리기 위해 train 데이터의 loss와 accuracy 따로 저장\n",
        "                train_losses.append(epoch_loss)\n",
        "                train_accuracy.append(epoch_acc)\n",
        "            if phase == 'val': #그래프 그리기 위해 \bvalidation 데이터의 loss와 accuracy 따로 저장\n",
        "                val_losses.append(epoch_loss)\n",
        "                val_accuracy.append(epoch_acc)\n",
        "          \n",
        "            if phase == 'val' and epoch_acc > best_acc: #validation 모드에서 정확도가 최고 정확도 보다 높으면 업데이트\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict()) #최고 정확도를 가진 모델을 best_model_wts 변수에 저장\n",
        " \n",
        "        time_elapsed = time.time() - since #한 에포크 돌 때 소요되는 시간 측정(종료 시각 - 시작 시각) \n",
        "        print('Completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)) #계산한 시간 분과 초로 출력\n",
        "\n",
        "    #학습 종료 후 \n",
        "    print('Best validation Acc: {:4f}'.format(best_acc)) #validation 중 최고 정확도 출력\n",
        "\n",
        "    #train과 validation의 loss, accuracy 그래프 출력 -> 과적합 여부 등 판단\n",
        "    plt.plot(range(1,len(train_losses)+1),train_losses,'bo',label = 'training loss')\n",
        "    plt.plot(range(1,len(val_losses)+1),val_losses,'r',label = 'validation loss')\n",
        "    plt.legend()\n",
        "    plt.plot(range(1,len(train_accuracy)+1),train_accuracy,'co',label = 'training accuracy')\n",
        "    plt.plot(range(1,len(val_accuracy)+1),val_accuracy,'m',label = 'validation accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    #정확도가 가장 높았던 모델을 불러와서 반환\n",
        "    model.load_state_dict(best_model_wts) \n",
        "    return model"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "id": "EQ6wBtMAs6pw",
        "outputId": "21ddda76-937d-4ca5-dd95-986788f9171b"
      },
      "source": [
        "# 전이학습 실행\n",
        "model = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=EPOCH)\n",
        "\n",
        "# 반환 받은 정확도가 가장 높았던 모델을 torch.save 이용해서 저장 (모델 별로 이름 변경해서 저장!)\n",
        "torch.save(model, '/content/drive/MyDrive/plant-leaf-dataset/efficientnet_b0.pt')"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------- epoch 1 ----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 1.1250 Acc: 0.6650\n",
            "val Loss: 0.7011 Acc: 0.7802\n",
            "Completed in 0m 24s\n",
            "-------------- epoch 2 ----------------\n",
            "train Loss: 0.6851 Acc: 0.7836\n",
            "val Loss: 1.0155 Acc: 0.6879\n",
            "Completed in 0m 24s\n",
            "-------------- epoch 3 ----------------\n",
            "train Loss: 0.6034 Acc: 0.8015\n",
            "val Loss: 1.4153 Acc: 0.6267\n",
            "Completed in 0m 24s\n",
            "-------------- epoch 4 ----------------\n",
            "train Loss: 0.5476 Acc: 0.8184\n",
            "val Loss: 2.1236 Acc: 0.5534\n",
            "Completed in 0m 24s\n",
            "-------------- epoch 5 ----------------\n",
            "train Loss: 0.5134 Acc: 0.8276\n",
            "val Loss: 2.1195 Acc: 0.5789\n",
            "Completed in 0m 24s\n",
            "Best validation Acc: 0.780172\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhV5bX48e/KycwkBUQEQsALGDKZEJGKICi0iFNRqVgc4IK5RaveqihqBbQ/vLWCWlpQoXXA4oDUudAqt6HIBZRBcEBAZYwghCGREBIyrN8fOzmchAwnyUnOkPV5njycc/Z79l7ZnKy8efe71yuqijHGmOAX5u8AjDHG+IYldGOMCRGW0I0xJkRYQjfGmBBhCd0YY0KEJXRjjAkRdSZ0EekuIlkiskVEvhSRu6ppM05EPhORz0VktYikNk24xhhjaiJ1zUMXkS5AF1XdKCJtgA3Az1R1i0ebC4GvVPWoiFwGzFDVC5oycGOMMZWF19VAVfcD+8sfHxORr4CuwBaPNqs93rIW6ObjOI0xxtShzoTuSUTigTTg41qaTQSW1bWvjh07anx8fH0Ob4wxLd6GDRsOqWqn6rZ5ndBFpDXwN+C/VfWHGtoMw0noF9WwPRPIBIiLi2P9+vXeHt4YYwwgIrtr2ubVLBcRicBJ5otU9c0a2qQAfwauVtXD1bVR1fmqmqGqGZ06VfsLxhhjTAN5M8tFgL/gXPR8soY2ccCbwE2qut23IRpjjPGGN0Mug4CbgM9FZFP5aw8CcQCq+iwwDegAzHPyPyWqmuH7cI0xxtTEm1kuqwCpo80kYFJjgykuLiY7O5vCwsLG7sqEiOjoaLp160ZERIS/QzEm4NVrlktTy87Opk2bNsTHx1Pe0zctmKpy+PBhsrOz6dmzp7/DMSbgBdSt/4WFhXTo0MGSuQFAROjQoYP9xWaMlwIqoQOWzE0l9nkwxnsBNeRijAkyZWXwl79AdjaIQFiY8+X5uOpzbx63hPc0QWfFErqH3NxcXnnlFW677bZ6v3fUqFG88sornHHGGTW2mTZtGkOGDGH48OGNCROA+Ph41q9fT8eOHRu9L2Ma7IEH4Pe/93cUwef+++F3v/P5boM6oS9aBA89BHv2QFwczJwJ48Y1fH+5ubnMmzev2oReUlJCeHjNp2vp0qV17v/RRx9teHDGBJp585xkPnkyzJ3rvFZW5nyp+uZxsL+/pn1deGHT/J+oql+++vfvr1Vt2bLltNdq8te/qsbGqjpnyPmKjXVeb6jrr79eo6OjNTU1Ve+9917NysrSiy66SK+88krt3bu3qqpeffXVmp6erv369dPnnnvO/d4ePXpoTk6O7ty5U88991ydNGmS9uvXT0eMGKEFBQWqqnrLLbfoG2+84W4/bdo0TUtL06SkJP3qq69UVfXgwYM6fPhw7devn06cOFHj4uI0JyfntFgrjqeqOnv2bE1MTNTExER96qmnVFU1Pz9fR40apSkpKZqYmKivvfaaqqref//9mpCQoMnJyXrPPfc0/GQ1o/p8Lkwzefdd1bAw1SuuUC0u9nc0LQqwXmvIq0Gb0Hv0qJzMK7569PB6F6fZuXOnJiYmup9nZWVpbGys7tixw/3a4cOHVVW1oKBAExMT9dChQ+XxnEroLpdLP/30U1VVHTNmjL788suqenpCnzNnjqqqzp07VydOnKiqqrfffrs+9thjqqq6bNkyBWpN6OvXr9ekpCTNz8/XY8eOab9+/XTjxo26ZMkSnTRpkrt9bm6uHjp0SPv06aNlZWWqqnr06NGGn6xmZAk9wHzyidN76t9fNT/f39G0OLUl9ICb5eKtPXvq93pDDRgwoNIc6Dlz5pCamsrAgQPZu3cvX3/99Wnv6dmzJ+eddx4A/fv3Z9euXdXu+5prrjmtzapVqxg7diwAI0eOpH379rXGt2rVKkaPHk2rVq1o3bo111xzDR999BHJycl8+OGH3H///Xz00Ue0a9eOdu3aER0dzcSJE3nzzTeJjY2t7+kwLd3OnXDFFXDmmfD++9Cqlb8jMh6CNqHHxdXv9YZq5fGBXbFiBcuXL2fNmjVs3ryZtLS0audIR0VFuR+7XC5KSkqq3XdFu9raNFSfPn3YuHEjycnJ/OY3v+HRRx8lPDycTz75hOuuu47333+fkSNH+vSYJsQdOQKXXQbFxbB0KZx1lr8jMlUEbUKfOROqdjBjY53XG6pNmzYcO3asxu15eXm0b9+e2NhYtm7dytq1axt+sBoMGjSIxYsXA/DBBx9w9OjRWtsPHjyYt99+m4KCAo4fP85bb73F4MGD2bdvH7Gxsdx4441MmTKFjRs3kp+fT15eHqNGjeKpp55i8+bNPo/fhKjCQrj6aqeH/vbbkJDg74hMNYJ2lkvFbBZfznLp0KEDgwYNIikpicsuu4zLL7+80vaRI0fy7LPPkpCQQN++fRk4cGAjvoPqTZ8+nRtuuIGXX36ZH//4x5x11lm0adOmxvbp6emMHz+eAQMGADBp0iTS0tL45z//yZQpUwgLCyMiIoJnnnmGY8eOcfXVV1NYWIiq8uST1RbPNKaysjIYPx5WrYJXX4UhQ/wdkalBnWuKNpWMjAytusDFV199RUIL/81fVFSEy+UiPDycNWvWMHnyZDZt2lT3G0OYfS787P77nemJjz8O993n72haPBHZoDVUsw3aHnqo2rNnDz//+c8pKysjMjKSBQsW+Dsk05J5zjWfMsXf0Zg6WEIPML179+bTTz/1dxjGwHvvwR13wJVXwpw5TXKruvGtoL0oaoxpQuvWwdixkJ7ujJvXcpe0CRzeLEHXXUSyRGSLiHwpIndV00ZEZI6IfCMin4lIetOEa4xpcjbXPGh582u3BLhHVTeKSBtgg4h8qKpbPNpcBvQu/7oAeKb8X2NMMPGca75sGXTu7O+ITD3U2UNX1f2qurH88THgK6BrlWZXAwvL70xdC5whIl18Hq0xpul4zjV/5x0491x/R2TqqV5j6CISD6QBH1fZ1BXY6/E8m9OTPiKSKSLrRWR9Tk5O/SINUK1btwZg3759XHfdddW2GTp0KFWnaFb19NNPU1BQ4H4+atQocnNzGx3fjBkzmDVrVqP3Y0Kc51zzhQth8GB/R2QawOuELiKtgb8B/62qPzTkYKo6X1UzVDWjU6dODdlFwDr77LNZsmRJg99fNaEvXbq01trqxvjUAw/A6687UxSvv97f0ZgG8iqhi0gETjJfpKpvVtPkO6C7x/Nu5a8FlalTpzK3oq4zp3q3+fn5XHrppaSnp5OcnMw777xz2nt37dpFUlISACdOnGDs2LEkJCQwevRoTpw44W43efJkMjIySExMZPr06YBT8Gvfvn0MGzaMYcOGAc4CFocOHQLgySefJCkpiaSkJJ5++mn38RISErj11ltJTEzkJz/5SaXjVGfTpk0MHDiQlJQURo8e7S4rMGfOHPr160dKSoq7MNi///1vzjvvPM477zzS0tJqLYlgglzFXPPbboN77/V3NKYxairDWPEFCLAQeLqWNpcDy8rbDgQ+qWu/dZbPvesu1Ysv9u3XXXfVWpZy48aNOmTIEPfzhIQE3bNnjxYXF2teXp6qqubk5Og555zjLkHbqlUrVa1cenf27Nk6YcIEVVXdvHmzulwuXbdunaqeKr9bUlKiF198sW7evFlVK9c393xeU3nc2sr0epo+fbo+8cQTqqqanJysK1asUFXVhx9+WO8qPx9dunTRwsJCVT1VUveKK67QVatWqarqsWPHtNiPNa+tfG4TqqhrfuWVVtc8SNDI8rmDgJuAS0RkU/nXKBH5pYj8srzNUmAH8A2wAKj/Gm4BIC0tjYMHD7Jv3z42b95M+/bt6d69O6rKgw8+SEpKCsOHD+e7777jwIEDNe5n5cqV3HjjjQCkpKSQkpLi3rZ48WLS09NJS0vjyy+/ZMuWLTXtBqi5PC54X6YXnMJiubm5XHzxxQDccsstrFy50h3juHHj+Otf/+pelWnQoEHcfffdzJkzh9zc3FpXazJByuaah5w6/wdVdRVOz7u2Ngrc7qugACgfWmhuY8aMYcmSJXz//fdcXz6WuGjRInJyctiwYQMRERHEx8dXWza3Ljt37mTWrFmsW7eO9u3bM378+Abtp0LVMr11DbnU5O9//zsrV67kvffeY+bMmXz++edMnTqVyy+/nKVLlzJo0CD++c9/cq7NeggdNtc8JNmdolVcf/31vPbaayxZsoQxY8YATu/2zDPPJCIigqysLHbv3l3rPoYMGcIrr7wCwBdffMFnn30GwA8//ECrVq1o164dBw4cYNmyZe731FS6t6byuPXVrl072rdv7+7dv/zyy1x88cWUlZWxd+9ehg0bxuOPP05eXh75+fl8++23JCcnc//993P++eezdevWeh/TBCibax6y7G+sKhITEzl27Bhdu3alSxdnKv24ceO48sorSU5OJiMjo86e6uTJk5kwYQIJCQkkJCTQv39/AFJTU0lLS+Pcc8+le/fuDBo0yP2ezMxMRo4cydlnn01WVpb79ZrK49Y2vFKTl156iV/+8pcUFBTQq1cvXnjhBUpLS7nxxhvJy8tDVbnzzjs544wzePjhh8nKyiIsLIzExEQuu+yyeh/PBCDPuebLl9tc8xBj5XNNwLPPhY+UlcEvfuFMT3ztNZueGKRqK59rQy7GtBQ21zzkWUI3piWwueYtgiV0Y0KdZ13zP/zB6pqHMEvoxoQym2veolhCNyZU2VzzFscSujGhyOaat0iW0D3k5uYyb968Br3Xm3K306ZNY/ny5Q3avzFes7rmLVZQJ/RFBw4Qv2YNYStWEL9mDYtqqa/ijdoSeklJSa3v9abc7aOPPsrw4cMbHJ8/1PV9mwBjdc1btKBN6IsOHCBz2zZ2FxWhwO6iIjK3bWtUUp86dSrffvst5513HlOmTGHFihUMHjyYq666in79+gHws5/9jP79+5OYmMj8+fPd760od1tbWdvx48e7a6bHx8czffp0d0neilvrc3JyGDFiBImJiUyaNIkePXq4y+h6qq4ML8C6deu48MILSU1NZcCAARw7dozS0lLuvfdekpKSSElJ4Y9//GOlmAHWr1/P0KFDAads8E033cSgQYO46aab2LVrF4MHDyY9PZ309HRWr17tPt7jjz9OcnIyqamp7vOXnn5qSdmvv/660nPTxGyuectWUxnGpv6qs3xuHXqsXq1kZZ321WP1aq/3UZVnCVxV1aysLI2NjdUdO3a4X6sof1tQUKCJiYl66NAhJ57ycre1lbW95ZZb9I033nC3nzNnjqqqzp07VydOnKiqqrfffrs+9thjqqq6bNkyBSqV1a0ah2cZ3qKiIu3Zs6d+8sknqqqal5enxcXFOm/ePL322mvdJXAr3utZsnfdunV68cUXq6pTcjc9PV0LCgpUVfX48eN64sQJVVXdvn27VvzfLV26VH/84x/r8ePHK+136NCh7u//gQcecH+fDWXlc700d64qqN52m2p5eWcTeqilfG7QzmHaU1RUr9cbasCAAfTs2dP9fM6cObz11lsA7N27l6+//poOHTpUeo+3ZW2vueYad5s333TWDVm1apV7/yNHjqR9+/bVvnfx4sXMnz+fkpIS9u/fz5YtWxARunTpwvnnnw9A27ZtAVi+fDm//OUv3SVwf/SjH9X5fV911VXExMQAUFxczK9+9Ss2bdqEy+Vi+/bt7v1OmDCB2NjYSvudNGkSL7zwAk8++SSvv/46n3zySZ3HM41kc80NQVycKy4qit3VJO84j5KyvtDKY6rXihUrWL58OWvWrCE2NpahQ4dWW/7W27K2Fe1cLle9xqp9VYY3PDycsrIygNPe7/l9P/XUU3Tu3JnNmzdTVlZGdHR0rfu99tpreeSRR7jkkkvo37//ab/wjI/ZXHNTrs4xdBF5XkQOisgXNWxvJyLvichmEflSRCb4PszTzezVi9iwyuHHhoUxs1evBu+zphK2FfLy8mjfvj2xsbFs3bqVtWvXNvhYNRk0aBCLFy8G4IMPPnAvE+eppjK8ffv2Zf/+/axbtw6AY8eOUVJSwogRI3juuefcvzSOHDkCOGPoGzZsAOBvf/tbjTHl5eXRpUsXwsLCePnllyktLQVgxIgRvPDCC+61UCv2Gx0dzU9/+lN31UnThGyuufHgzUXRF4GRtWy/HdiiqqnAUGC2iEQ2PrTajevcmfl9+9IjKgoBekRFMb9vX8Y1Yr5thw4dGDRoEElJSUyZMuW07SNHjqSkpISEhASmTp3KwIEDG/EdVG/69Ol88MEHJCUl8cYbb3DWWWfRpk2bSm08y/D+4he/cJfhjYyM5PXXX+eOO+4gNTWVESNGUFhYyKRJk4iLiyMlJYXU1FR3rfbp06dz1113kZGRgcvlqjGm2267jZdeeonU1FS2bt3q7r2PHDmSq666ioyMDM477zxmzZrlfs+4ceMICwvjJz/5ia9Pkalgc81NFV6VzxWReOB9VU2qZtsDOAtE3w7EAx8CfVS1rLZ9Wvnc6hUVFeFyuQgPD2fNmjVMnjyZTZs2+Tuseps1axZ5eXn89re/bfS+7HNRjcJCGDECPvnEqWtu0xNbjNrK5/pisO1PwLvAPqANcH1dydzUbM+ePfz85z+nrKyMyMhIFixY4O+Q6m306NF8++23/Otf//J3KKHJc675a69ZMjduvkjoPwU2AZcA5wAfishHqvpD1YYikglkAsTFxfng0KGnd+/efPrpp/4Oo1EqZumYJmJzzU0NfHFj0QTgzfIpkt8AO4Fq7zVW1fmqmqGqGZ06dfLBoY1pYayuuamFLxL6HuBSABHpDPQFdvhgv8YYTzbX3NShziEXEXkVZ/ZKRxHJBqYDEQCq+izwW+BFEfkcEOB+VT39XnVjTMPZXHPjhTo/Fap6Qx3b9wE2N82YpmJzzY2XgrY4V6Bo3bo1APv27eO6666rts3QoUOpOkWzqqefftp9gw54V47XtAA219zUgyV0Hzn77LPdlRQbompC96YcbyBRVXcZAeMjVtfc1JMldA9Tp05l7ty57uczZsxg1qxZ5Ofnc+mll7pL3b7zzjunvXfXrl0kJTn3XZ04cYKxY8eSkJDA6NGjK9Vyqa7s7Zw5c9i3bx/Dhg1j2LBhQOXStk8++SRJSUkkJSXx9NNPu49XU5leT++99x4XXHABaWlpDB8+nAPl5YXz8/OZMGECycnJpKSkuG/9/8c//kF6ejqpqalceumllc5DhaSkJHbt2sWuXbvo27cvN998M0lJSezdu7deZX2HDBlS6aapiy66iM2bN3v9/xXSrK65aYiayjA29Vdd5XO337VdN1680adf2+/aXmtZyo0bN+qQIUPczxMSEnTPnj1aXFyseXl5qqqak5Oj55xzjpaVlydt1aqVqlYuvTt79mydMGGCqqpu3rxZXS6Xrlu3TlWrL3urWrmUrefz9evXa1JSkubn5+uxY8e0X79+unHjxlrL9Ho6cuSIO9YFCxbo3Xffraqq9913n951112V2h08eFC7devmLhdcEev06dP1iSeecLdNTEzUnTt36s6dO1VEdM2aNe5t9Snr++KLL7pj2LZtm1b3mVBtoeVz77vPKYX7+9/7OxITYKilfK710D2kpaVx8OBB9u3bx+bNm2nfvj3du3dHVXnwwQdJSUlh+PDhfPfdd+6ebnVWrlzJjTfeCEBKSgopKSnubYsXLyY9PZ20tDS+/PJLtmzZUmtMq1atYvTo0bRq1YrWrVtzzTXX8NFHHwHelenNzs7mpz/9KcnJyTzxxBN8+eWXgFP69vbbb3e3a9++PWvXrmXIkCHucsHelNnt0aNHpZo21X1/27ZtO62sb3h4OGPGjOH999+nuLiY559/nvHjx9d5vBbB5pqbBgrYuU+9n+7tl+OOGTOGJUuW8P3333N9+V14ixYtIicnhw0bNhAREUF8fHyDytX6quxtBW/K9N5xxx3cfffdXHXVVaxYsYIZM2bU+zieZXahcqldzzK79f3+YmNjGTFiBO+88w6LFy92V35s0WyuuWkE66FXcf311/Paa6+xZMkSxowZAzjlY88880wiIiLIyspi9+7dte5jyJAh7oqGX3zxBZ999hlQc9lbqLl07+DBg3n77bcpKCjg+PHjvPXWWwyux3hqXl4eXbt2BeCll15yvz5ixIhK1wuOHj3KwIEDWblyJTt37gQql9nduHEjABs3bnRvr6q+ZX3BWQzjzjvv5Pzzz69xMY8Ww+aam0ayhF5FYmIix44do2vXrnTp0gVwSsGuX7+e5ORkFi5cyLl1zDaYPHky+fn5JCQkMG3aNPr37w/UXPYWIDMzk5EjR7ovilZIT09n/PjxDBgwgAsuuIBJkyaRlpbm9fczY8YMxowZQ//+/enYsaP79d/85jccPXqUpKQkUlNTycrKolOnTsyfP59rrrmG1NRU918o1157LUeOHCExMZE//elP9OnTp9pj1besLzhDRW3btrW66TbX3PiAV+Vzm4KVzzXgzN8fOnQoW7duJSys+v5FyH8ujhyBCy+Egwdh9WqbnmhqVVv5XOuhG79ZuHAhF1xwATNnzqwxmYc8m2tufMgG6Yzf3Hzzzdx8883+DsN/rK658bGA6xb5awjIBKaQ/jxYXXPjYwGV0KOjozl8+HBo/xAbr6kqhw8fJjo62t+h+J7NNTdNIKCGXLp160Z2djY5OTn+DsUEiOjoaLp16+bvMHzL5pqbJhJQCT0iIsJ9l6IxIcnmmpsmFFBDLsaENJtrbppYnQldRJ4XkYMi8kUtbYaKyCYR+VJE/u3bEI0JAVbX3DQDb3roLwIja9ooImcA84CrVDURGOOb0IwJETbX3DSTOhO6qq4EjtTS5BfAm6q6p7z9QR/FZkzws7rmphn5Ygy9D9BeRFaIyAYRacF3ihhThc01N83IF5fYw4H+wKVADLBGRNaq6vaqDUUkE8gEiIuL88GhjQlgNtfcNDNf9NCzgX+q6nFVPQSsBFKra6iq81U1Q1UzOnXq5INDGxOgbK658QNfJPR3gItEJFxEYoELgK98sF9jgpPNNTd+UucnTUReBYYCHUUkG5gORACo6rOq+pWI/AP4DCgD/qyqNU5xNCak2Vxz40d1JnRVvcGLNk8AT/gkImOClc01N35mfwsa4wuec82XL7e55sYvLKEb01hW19wECKvlYkxj2VxzEyAsoRvTGDbX3AQQS+jGNJTNNTcBxhK6MQ1hc81NALKEbkx92VxzE6AsoRtTHzbX3AQw+zvRGG/ZXHMT4CyhG+MNm2tugoANuRjjjYq55k88YXPNTcCyhG5MXSrmmt9+O9xzj7+jMaZGltCNqY3NNTdBxBK6MTWpmGvev78z19zl8ndExtTKErox1amYa965s9NLt7nmJgjUmdBF5HkROSgitS5aISLni0iJiFznu/CM8YOKueYlJTbX3AQVb3roLwIja2sgIi7gceADH8RkjP8cPuzMNd+1C955B/r29XdExnitzoSuqiuBI3U0uwP4G3DQF0EZ0+xUnfnlCQmwdi0sXAgXXeTvqIypl0aPoYtIV2A08EzjwzHGD7Kz4aqr4IYbID4eNm6En//c31EZU2++uCj6NHC/qpbV1VBEMkVkvYisz8nJ8cGhjWmEsjJ45hno1w/+939h9mxYswaSk/0dmTEN4otb/zOA18SZn9sRGCUiJar6dtWGqjofmA+QkZGhPji2MQ2zbRvceit89BFceinMnw+9evk7KmMapdEJXVV7VjwWkReB96tL5sYEhOJimDULHnkEYmLg+eedGi12w5AJAXUmdBF5FRgKdBSRbGA6EAGgqs82aXTG+NKGDTBpEmzaBNddB3/8I5x1lr+jMsZn6kzoqnqDtztT1fGNisaYplBQADNmwJNPOotSvPkmjB7t76iM8Tkrn2tCW1aWM1b+7bdO7/yJJ+CMM/wdlTFNwm79N6EpNxcyM+GSS5zn//oXLFhgydyENEvoJvS8/bYzFfEvf4EpU+Czz2DYMH9HZUyTsyEXEzq+/94pdbtkCaSkwLvvQkaGv6MyptlYD90EP1V48UWnV/7eezBzJqxfb8nctDjWQzfBbedO+K//gg8/dGqv/PnPVlDLtFjWQzfBqbQUnnoKkpKcYlrz5sG//23J3LRo1kM3wefzz50piJ984ixCMW8edO/u76iM8TvroZvgUVQE06ZBeroz1PLqq86FT0vmxgDWQzfBYvVqp1f+1Vdw443OcEvHjv6OypiAYj10E9jy8+HOO50LnsePw9Kl8PLLlsyNqYYldBO4/vEPSEyEP/0JfvUr+OILZ61PY0y1LKGbwHPoENx0k5O8W7WCVatgzhxo08bfkRkT0Cyhm8Ch6lzo7NfPWd/z4Yfh00/hwgv9HZkxQcEuiprAsHcv3HYbvP8+DBjgLAlnS8EZUy/WQzf+VbGuZ2KiUxHxySedGS2WzI2ptzoTuog8LyIHReSLGraPE5HPRORzEVktIqm+D9OEpG3bYOhQp2d+wQXORc9f/xpcLn9HZkxQ8qaH/iIwspbtO4GLVTUZ+C3li0AbU6PiYnjsMUhNde76fP55+OAD6Nmz7vcaY2rkzRJ0K0Ukvpbtqz2ergW6NT4sE7I2bICJE2HzZlvX0xgf8/UY+kRgmY/3aUJBQQHcd59zwfPgQXjrLXjjDUvmxviQz2a5iMgwnIR+US1tMoFMgLi4OF8d2gQ6z3U9b70Vfv97WwrOmCbgkx66iKQAfwauVtXDNbVT1fmqmqGqGZ06dfLFoU0gy811Evgll4CIM4tl/nxL5sY0kUYndBGJA94EblLV7Y0PyYSEinU9X3jBGWqxdT2NaXJ1DrmIyKvAUKCjiGQD04EIAFV9FpgGdADmiQhAiara2l8tlee6nqmpzpJw/fv7OypjWgRvZrncUMf2ScAkn0VkglPFup733ONcAH3sMbj3XoiI8HdkxrQYduu/abwdO5x1PZcvh8GDYcECWwrOGD8Iqlv/Fy2C+HgIC3P+XbTI3xG1cKWlzq36ycnw8cfOLfwrVlgyN8ZPgqaHvmgRZGY6f80D7N7tPAcYN85/cbVYn3/u3CC0bp2zruczz0A3u6fMGH8Kmh76Qw+dSl30cFgAABXcSURBVOYVCgqc100z8lzXc9euU+t6WjI3xu+Cpoe+Z0/9XjdNwHNdz5tuctb17NDB31EZY8oFTQ+9phtL7YbTZnDsmDMVsWJdz2XLYOFCS+bGBJigSegzZ0JsbOXXYmOd100TWrYMkpJg7txT63qOrK34pjHGX4ImoY8b59w13qOHcxd5jx7Oc7sg2kQq1vUcNcpZ1/P//s/W9TQmwAXNGDo4ydsSeBNTddbzvPNOyMtzLoA++CBERfk7MmNMHYIqoZsmtncvTJ4Mf/+7U+b2L39xhluMMUEhaIZcTBPyXNczK8uZvbJ6tSVzY4KM9dBbum3bnBK3H30Ew4c7FyZsKThjgpL10Fsqz3U9v/jCKXNr63oaE9Ssh94SrV/v3CC0eTOMGePMXrGl4IwJetZDb0kKCmDKFLjgAsjJcRahWLzYkrkxIcJ66C2F57qemZnw+OO2FJwxIabOHrqIPC8iB0Xkixq2i4jMEZFvROQzEUn3fZimwQ4cqLyuZ1YWPPecJXNjQpA3Qy4vArXd630Z0Lv8KxN4pvFhmUbLyXHW8uzZs/K6nkOH+jsyY0wT8WYJupUiEl9Lk6uBhaqqwFoROUNEuqjqfh/FaOrj8GGYNQv++Ec4ccK5tfbhh6F3b39HZoxpYr4YQ+8K7PV4nl3+2mkJXUQycXrxxFmZRN86etRZPegPf4D8fBg71rlt/9xz/R2ZMaaZNOssF1Wdr6oZqprRqVOn5jx06MrLg0cecdbk+3//Dy67zFlN6JVXLJkb08L4oof+HdDd43m38tdMU/rhB2f++OzZkJsL11wD06dDSoq/IzPG+IkveujvAjeXz3YZCOTZ+HkTys+H3/3Oudj58MMwZAhs3Ah/+5slc2NauDp76CLyKjAU6Cgi2cB0IAJAVZ8FlgKjgG+AAmBCUwXbohUUwLx5zvzxQ4ecOuWPPAIZGf6OzBgTILyZ5XJDHdsVuN1nEZnKTpyAZ591EvmBA/DTnzqJ/IIL/B2ZMSbA2J2igaqwEBYsgP/5H9i/Hy691BlWGTTI35EZYwKUJfRAU1TkLCzx2GPw3Xdw8cXOCkJDhvg7MmNMgLOEHihOnoQXX3SmHu7d6/TEFy6EYcOcW/aNMaYOVm3R34qL4fnnoW9f+K//gq5dnbrkH310qv6KMcZ4wRK6v5SUOD3whASYOBE6dYKlS52l30aMsERujKk3S+jNrbQUFi2Cfv3gllugbVt47z34+GPnLk9L5MaYBrKE3lzKyuD1152Fl2+8EWJi4K23YMMGuOIKS+TGmEazhN7UyspgyRLnLs6xY8HlgjfegE8/hZ/9zBK5McZnLKE3FVVnibe0NGfdztJSZ/rhZ5/BdddBmJ16Y4xvWVbxNVV4/33o3x9Gj3bu9PzrX+GLL+D66y2RG2OajGUXX1GFZcucW/KvvNIpa/vSS7Bli7PIhMvl7wiNMSHOEnpjqcKHH8KFFzoFs3JynDs9t26Fm2+GcLt3yxjTPCyhN0ZWlnNL/k9+4tym/9xzsG0b/Od/QkSEv6MzxgSYRQcOEL9mDWErVhC/Zg2LDhzw6f4toTfEypXOYsuXXAI7d8LcufD115CZCZGR/o7OmGbT1AkqlCw6cIDMbdvYXVSEAruLisjcts2n58wSen2sXg3DhzsFs7Ztc1YM+uYbuO02iIryd3TGNKvmSFCh5KEdOygoK6v0WkFZGQ/t2OGzY3iV0EVkpIhsE5FvRGRqNdvjRCRLRD4Vkc9EZJTPIgwEH38MI0c6BbM+/9xZjHnHDrjjDoiO9nd0xvhFcySoULKnqKherzdEnQldRFzAXOAyoB9wg4j0q9LsN8BiVU0DxgLzfBahP61fD5dfDgMHOnd0PvGEk8h//WvnTk8TcmwIwXvNkaBCSVwNf8XX9HpDeNNDHwB8o6o7VPUk8BpwdZU2CrQtf9wO2OezCP3h00/h6qvh/PNh7VpnkYmdO+Hee6FVK39HZ5qIDSHUT3MkqFAys1cvYqvchxIbFsbMXr18dgxvEnpXYK/H8+zy1zzNAG4sX3N0KXCHT6Jrbp9/DtdeC+npzoXP3/7WSeRTp0Lr1v6OrkGsx+k9G0Kon+ZIUKFkXOfOzO/blx5RUQjQIyqK+X37Mq5zZ58dw1eTpG8AXlTV2SLyY+BlEUlS1Uo/HSKSCWQCxMXF+ejQPvDll846nW+84VQ/nDED7roLzjjD35E1SkWPsyJJVfQ4AZ9+iEKFDSHUT8Vn6KEdO9hTVERcVBQze/Wyz1YtxnXu3KTnx5uE/h3Q3eN5t/LXPE0ERgKo6hoRiQY6Agc9G6nqfGA+QEZGhjYk4PzP8tk3fx+xfWKJ6RNDbJ9YontEI64GFLnauhUefdSpsdKqFfzmN3D33dC+fUNCCzi19Tjth+50cVFR7K4medsQQs2aOkGZ+vEmoa8DeotIT5xEPhb4RZU2e4BLgRdFJAGIBnJ8GWiFEztOcOCvByjNK3W/JpFCzDkx7gQf0yeG2L6xxPaJJeLMCKRqRcOvv3aGUxYtci5uTp0K99wDHTo0Rch+Yz3O+pnZq1elv2jAhhBMcKkzoatqiYj8Cvgn4AKeV9UvReRRYL2qvgvcAywQkV/jXCAdr6oN6oHXpdPPOtHxaEeKDxVzYvsJCrYXULCtwP34yD+OoEWnDu1q6zqV5DsVEfPpe8SuepWYyIOE33MPTJnirBYUgqzHWT82hGCCnTRR3q1TRkaGrl+/3uf71VKlcG+hO8Gf2H6Cgs2HObHxEIX5sXheB448K9Ldm/fs3cf0iiEsMvjvuao6hg5Oj9PXF2KMMc1HRDaoakZ120KucpS4hJj4GGLiY/hRwnF47ElY8xcQoXTyZArH3EVBbutKCf/QO4coPlh8aidhEN0zutI4fcW/Ud2ikLDgWJTCepzGtCwhl9ABp1DW//wPLFjgVEO89VZ44AFc3brRCqhuJnlxbjEnvj5RafjmxPYT5K7Mpez4qR5uWEwYMb1jqk32ER0CryCXXbQypuUIrYT+/ffwu9/Bs886KwT953/CQw+BF1MkI86IIOL8CNqe37bS66rKyf0nTw3flP+b/3k+h94+hJacGrIK/1F45UTft/zf/4jBFWv10I0xTSs0EvrBg/D44/DMM3DyJIwf7yTynj0bvWsRIersKKLOjqL90MrTGcuKyyjcVWW8fnsBuf/K5cDCyjfwRHWPOq1HH9Mnhuj4aMLCg3+83hjjf8Gd0A8dcuqr/OlPUFgIN93kzCX/j/9olsOHRYQR2zuW2N6xdLi88pTH0uOlnPjm9Fk4B189SEluibudRFQz5bL838izIk+fcmmMMTUIzoR+5AjMnu2Urz1+HH7xC5g2Dfr08Xdkbq5WLlqntqZ1auWSAapK8eHi03r1J7af4OgHRykrPDVe72rtOj3R940htncs4e2C87/OGNN0gi8rvPOO0xPPz3cWXZ42DRIS/B2V10SEyI6RRHaMpN2F7Spt0zKlaG/RaYn+h09+4ODig+Bx02dE54hqL8zGnBNDWNSpIZxFi5zRpz17nEsJM2c6S5waY0JP8CX0lBS47DJ4+GFISvJ3ND4lYUJ0j2iie0TDiMrbyorKOLHjhJPotxW4k/3h9w/z/YHvTzUMg+ge0cT0iWGvxvJOViydimMQoji8O5LMW8MBsaRuTAgKqhuLFh04YHOqq1GSV0LB15V79QXbCsj59AQxWlqp7UmEPFcU5wyIJLJLJFFnRxHZJdL9VfE8okNE0My3N6YlCYkbi6xyYM3C24XTNqMtbTMqT7kME6U9J+nKCTpykg4U0YGTdCg9Se/YIgq+cmbkeF6krSDhQuRZkUSeXZ7ou0RVftylfFunyIYVRjPG+FzQJHSrHFh/cT2E3bujOELl2i09esDM5aeel54o5eT+k5zcf5Ki/UXO432nHhd+W0jeqjxKDp+e+HFB5JlOcncn+mp6/pGdIwmLsOmZxjSloEnoVjmw/mbOhMxMKCg49VpsrPO6J1eMi5heTg2b2pQVlXHywEmK9hW5fwGc3H/qeVF2ET988gPFOcVOiTZPAhGdIk5L9qf1/M+KrHRR1xjjvaBJ6FY5sP4qLnz6apZLWFQY0XHRRMfVvjB2WXEZxQeLnR7+Po+ev8fj/M35nPz+ZKWZOxXCO4RXGtapqefvirG7b43xFDQJ3WpVN8y4cc0/TTEsIoyorlFEda39l62WKidzTp42xOPZ6y/YWsDJ/ScrlVioEH5GeLUXdKs+Dm8dNB9zYxolaD7pVjkw9IhLiDoriqizoiCt5nZa5tyMVTXZez7+4f9+oGh/UaVa+BVcrV3VXtCt+tjV1mV35pqgFlTTFo2pjapScrSkxou7no/LCk4f6wmLCXP37qO6RxEVF+XcFxAX7X4c3jZo+kAmRDV62qKIjAT+gLNi0Z9V9XfVtPk5MAPncthmVa26TJ0xTUpEiPhRBBE/iqBVYnVFkh2qSumx0mp7+tvXnGTPuiLarvqBMykivMrVXVc7V6UE7/k4Ki6KqC5RNo3T+E2dCV1EXMBcnHsXs4F1IvKuqm7xaNMbeAAYpKpHReTMpgrYmMYSEcLbhhPeNpxW555K/IsWQeazUFB+7T0M5ezok8yeWsjQhCIKdxdStKeIwj2FFO4u5IfVP1BytPJUTgkXIrtGVk72cdFE9YhyP7cxfdNUvPlkDQC+UdUdACLyGnA1sMWjza3AXFU9CqCqB30dqDFN7aGHKk/xLEPILozivhei2LWr+veUHCuhaG/lZF+0x3me+1EuRdlFUPlmXcJ/FF5jso/uEU1k50i7S9c0iDcJvSuw1+N5NnBBlTZ9AETk/3CGZWao6j+q7khEMoFMgDgvFp0wpjnt2VO/1wHC24QT3i+cVv2qH+LRUqVofxFFuysn+8I9hRTuLCT337mU5lXO+BIhRHWvJtnHOXV+orpH2YIpplq++tsvHOgNDAW6AStFJFlVcz0bqep8YD44F0V9dGxjfCIuDnbvrv71hhKXEN0tmuhu0bQb1K7aNiV5JaeSfflwTsXj3P/NpWhf0Wnz9SM6RlSf7MsfR5wZYTN2WiBvEvp3QHeP593KX/OUDXysqsXAThHZjpPg1/kkSmOagbd31vpaeLtwWie3pnVy62q3lxWXcXLfydOSfdGeIgq2FXDkgyOV1r0FkCipPKxT5SJuVPcoXNHWy6+LlillJ8ooPV5KaUEpZcfLKC0opfR4KWUFZZX+rc/2szPPJu5+349SeJPQ1wG9RaQnTiIfC1SdwfI2cAPwgoh0xBmC2eHLQI1par6+s9ZXwiLCTpVVHnz6dlWlJLek2nH8oj1FHPnnEU7uP3laOYaIzhHVz9gpH+qJ6BD4vfyykjKfJdnS46e3LTtRza3MdZAowdXKhSvWRVirMFyxLlytXIS3C8d1touw2DCie9Z+t3VDeTUPXURGAU/jjI8/r6ozReRRYL2qvivO//psYCTOJaCZqvpabfu0eejGNJ+yk2UUZZ+e7D2fV01eYTFhNSb76LhoorpF8eobYTX+AlRVyop8nHCrbNfieo7cCoTFhlWbcCteb9T2WFeTT1utbR663VhkjHEvjehO8p4XccuHeooPFFd+j8BhIslRp8RDFGXESimd2pQSWeYk4epq9dRGwsU3SbaGtmHRYQH/V0ddQqIeujGm6XgujdgmvU21bUoLSynKPjVj53e/LiIqr5BOFKFADi4K1UVEWRg33dqwhGwllhvHeujGmAYJC4Pq0ocIlNV/6Nl4qbYeuv06NMY0SE3TOe0Wk5otWgTx8c4vw/h457kvWUI3xjTIzJnOtE5PzTHNM1gtWuRMi9292/nLZvdu57kvk7oldGNMg4wbB/PnO0saijj/zp/v/2megapqaQlwnj/0kO+OYWPoxhjTDHx1zcHG0I0xxs+a45qDJXRjjGkGzXHNwRK6McY0g+a45mA3FhljTDNp6kXbrYdujDEhwhK6McaECEvoxhgTIiyhG2NMiLCEbowxIcJvd4qKSA5QzQqOXukIHPJhOL4SqHFB4MZmcdWPxVU/oRhXD1XtVN0GvyX0xhCR9TXd+upPgRoXBG5sFlf9WFz109LisiEXY4wJEZbQjTEmRARrQp/v7wBqEKhxQeDGZnHVj8VVPy0qrqAcQzfGGHO6YO2hG2OMqSKgE7qIPC8iB0Xkixq2i4jMEZFvROQzEUkPkLiGikieiGwq/5rWDDF1F5EsEdkiIl+KyF3VtGn28+VlXP44X9Ei8omIbC6P65Fq2kSJyOvl5+tjEYkPkLjGi0iOx/ma1NRxeRzbJSKfisj71Wxr9vPlZVz+PF+7ROTz8uOetqKPz38mVTVgv4AhQDrwRQ3bRwHLAAEGAh8HSFxDgfeb+Vx1AdLLH7cBtgP9/H2+vIzLH+dLgNbljyOAj4GBVdrcBjxb/ngs8HqAxDUe+FNzni+PY98NvFLd/5c/zpeXcfnzfO0COtay3ac/kwHdQ1fVlcCRWppcDSxUx1rgDBHpEgBxNTtV3a+qG8sfHwO+ArpWadbs58vLuJpd+TnIL38aUf5V9YLS1cBL5Y+XAJeKiARAXH4hIt2Ay4E/19Ck2c+Xl3EFMp/+TAZ0QvdCV2Cvx/NsAiBZlPtx+Z/Ny0QksTkPXP6nbhpO786TX89XLXGBH85X+Z/pm4CDwIeqWuP5UtUSIA/oEABxAVxb/if6EhHp3tQxlXsauA+oaQVMv5wvL+IC/5wvcH4ZfyAiG0Qks5rtPv2ZDPaEHqg24tyemwr8EXi7uQ4sIq2BvwH/rao/NNdx61JHXH45X6paqqrnAd2AASKS1BzHrYsXcb0HxKtqCvAhp3rFTUZErgAOquqGpj5WfXgZV7OfLw8XqWo6cBlwu4gMacqDBXtC/w7w/G3brfw1v1LVHyr+bFbVpUCEiHRs6uOKSARO0lykqm9W08Qv56uuuPx1vjyOnwtkASOrbHKfLxEJB9oBh/0dl6oeVtWi8qd/Bvo3QziDgKtEZBfwGnCJiPy1Sht/nK864/LT+ao49nfl/x4E3gIGVGni05/JYE/o7wI3l18pHgjkqep+fwclImdVjB2KyACc89ykH+zy4/0F+EpVn6yhWbOfL2/i8tP56iQiZ5Q/jgFGAFurNHsXuKX88XXAv7T8SpY/46oyxnoVznWJJqWqD6hqN1WNx7ng+S9VvbFKs2Y/X97E5Y/zVX7cViLSpuIx8BOg6sw4n/5MBvSaoiLyKs4MiI4ikg1Mx7lIhKo+CyzFuUr8DVAATAiQuK4DJotICXACGNvUH2ycnspNwOfl468ADwJxHnH543x5E5c/zlcX4CURceH8Almsqu+LyKPAelV9F+cX0csi8g3ORfCxTRyTt3HdKSJXASXlcY1vhriqFQDny5u4/HW+OgNvlfdVwoFXVPUfIvJLaJqfSbtT1BhjQkSwD7kYY4wpZwndGGNChCV0Y4wJEZbQjTEmRFhCN8aYEGEJ3RhjQoQldGOMCRGW0I0xJkT8f3t0eVGROU5nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjkyMbUEuMqi"
      },
      "source": [
        "### 7. 모델 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPwYDjEHtCXm",
        "outputId": "c7acc6a3-f64e-4383-f2bc-4d4a11410459"
      },
      "source": [
        "# 전이학습 평가 전처리 (위에서 설명한 것과 동일)\n",
        "data_transforms = transforms.Compose([ \n",
        "        transforms.Resize([64,64]),  \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
        "        ])\n",
        "\n",
        "#경로 맞춰서 변경해 주세요!\n",
        "test_dataset = ImageFolder(root='/content/drive/MyDrive/plant-leaf-dataset/plant-leaf-new-dataset/test', transform=data_transforms) \n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "\n",
        "# 모델 평가 함수\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval() #모델을 평가 모드로 설정\n",
        "    test_loss = 0 #미니 배치 별로 loss를 합산해서 저장\n",
        "    correct = 0 #정확하게 예측한 수 저장   \n",
        "    with torch.no_grad(): #해당 메서드를 이용해서 parameter 업데이트 방지\n",
        "        for data, target in test_loader:  \n",
        "            data, target = data.to(DEVICE), target.to(DEVICE) #데이터와 라벨을 불러오면서 gpu에 태움  \n",
        "            output = model(data) #데이터를 모델에 입력           \n",
        "            test_loss += torch.nn.functional.cross_entropy(output,target, reduction='sum').item() #모델의 예측값과 정답값 사이의 loss 계산\n",
        "            pred = output.max(1, keepdim=True)[1]  #모델에 입력된 데이터가 12개의 클래스에 속할 확률값 출력, 이 중 가장 높은 값의 인덱스를 예측값으로 pred에 저장\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item() #target.view_as(pred)를 이용해 target의 텐서 구조를 pred의 텐서와 같은 모양으로 재정렬 (모델 만들 때 쓰는 view와 비슷 view는 숫자 직접 지정)\n",
        "                                                                  #eq는 비교 연산자로 pred와 target.view_as(pred)의 값이 일치하면 1, 일치하지 않으면 0 반환\n",
        "   \n",
        "    test_loss /= len(test_loader.dataset) #모든 미니 배치에서 합한 loss값을 배치 수로 나누어 loss값의 평균 구함\n",
        "    test_accuracy = 100. * correct / len(test_loader.dataset) #마찬가지로 정확도의 평균도 구함\n",
        "    \n",
        "    return test_loss, test_accuracy #계산한 Test 데이터의 loss와 정확도 반환\n",
        "\n",
        "# 전이학습 모델 평가 결과\n",
        "model=torch.load('/content/drive/MyDrive/plant-leaf-dataset/efficientnet_b0.pt') #torch.load를 이용해서 원하는 모델 불러오기!\n",
        "test_loss, test_accuracy = evaluate(model, test_loader) #평가 함수 이용해서 Test 데이터에 대한 loss 및 정확도 측정\n",
        "print('model test acc:  ', test_accuracy) #평가 정확도 출력"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model test acc:   78.40517241379311\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(과제) 한 가지 이상의 변화를 준 후 학습을 돌려서 결과와 함께 간단한 설명을 업로드 해주세요 😀\n",
        "\n",
        "예시 : 다른 전이학습 모델 사용, freeze 시키는 구간 변화, 직접 짠 모델과의 성능 비교, 데이터 수의 변화, optimizer에 대한 실험, epoch 늘리기, 등등"
      ],
      "metadata": {
        "id": "maEk9ITatoai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **(과제 설명)**\n",
        "\n",
        "efficientnetb0을 사용하여 학습해보았습니다 !\n",
        "\n",
        "모델 불러올 때 \n",
        "\n",
        "model = models.mobilenet_v2(pretrained=True)\n",
        "model.classifier[1].out_features = len(class_names)\n",
        "\n",
        "처럼 fc 아웃피쳐 수만 바꿔서 코드 실행시켰는데 오류가 나서 EfficientNet 모듈을 불러왔습니다\n",
        "\n",
        "Resize를 224,224로 바꿔 학습했을 때 오히려 정확도가 떨어지는 것을 볼 수 있었습니다.\n",
        "또 epoch과 batch_size를 바꿔가면서 실험했을 때 batch_size는 크게, epoch 수는 작게 하여 학습하는 것이 오히려 정확도가 높게 나오는 것을 볼 수 있었습니다.(위에서의 학습 과정처럼 epoch이 진행될 수록 val_acc가 줄어들고 val_loss는 증가하고 있음)\n",
        "\n",
        "\n",
        "lr은 1e-5는 학습이 잘 안되고 1e-4은 과적합이 발생하여 중간 정도인 0.0005로 설정하였습니다.\n",
        "\n",
        "test_acc는 val_acc보다 높은 78.4인 것을 확인할 수 있었습니다."
      ],
      "metadata": {
        "id": "_NfF1a5Y6Ygc"
      }
    }
  ]
}