{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3주차(금)_CNN실습(공유).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7d1c55c13d764a54bb06ec156f069da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_42f452642a63420b985fec7d997dc6b5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_57e72097660e4ce7bc5155076c6f87d2",
              "IPY_MODEL_ebbbfe2a50c245d7a847588dc61ebb31",
              "IPY_MODEL_bd5ef92b8eda45d0a042e4ba3977d06d"
            ]
          }
        },
        "42f452642a63420b985fec7d997dc6b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "57e72097660e4ce7bc5155076c6f87d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d85879cdaaf447ab989fe5160a250603",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1ccafc879f2c4abebbbddd4f10916c54"
          }
        },
        "ebbbfe2a50c245d7a847588dc61ebb31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_134433371d754024b1e7ebea9fd90947",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 52147035,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 52147035,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bd8272e7a2fb4e99873ed155d30300bc"
          }
        },
        "bd5ef92b8eda45d0a042e4ba3977d06d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_161814bfc38c41e584e055f3c0dd5356",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 49.7M/49.7M [00:00&lt;00:00, 108MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b0d8f13656d400597bd65494faef33d"
          }
        },
        "d85879cdaaf447ab989fe5160a250603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1ccafc879f2c4abebbbddd4f10916c54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "134433371d754024b1e7ebea9fd90947": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bd8272e7a2fb4e99873ed155d30300bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "161814bfc38c41e584e055f3c0dd5356": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b0d8f13656d400597bd65494faef33d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 0. 데이터 불러오기\n",
        "https://drive.google.com/file/d/1M8KwdmGm8EWCn_IEWAcctbUJBww-M3cF/view?usp=sharing\n",
        "\n",
        "1. 위 링크에 있는 zip 파일을 '드라이브에 바로가기 추가'하기(안되면 그냥 다운로드 후 내 드라이브에 업로드)\n",
        "2. GPU 설정 후, 드라이브 마운트\n",
        "3. zip 파일 풀기 (약 2분 소요)"
      ],
      "metadata": {
        "id": "TDekbT7bHvKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rD68wg6GRaeQ",
        "outputId": "60ae9c8c-bd4b-4a91-b388-cc4c4bba6cb1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip -uq “압축을 풀 zip 파일의 경로” -d “압축을 풀고자 하는 폴더의 경로”\n",
        "!unzip -uq /content/drive/MyDrive/plant-leaf-dataset.zip -d /content/drive/MyDrive/plant-leaf-dataset"
      ],
      "metadata": {
        "id": "0CrELDhBI3yO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAmOFLpdtXV5"
      },
      "source": [
        "### 1. 데이터 분할을 위한 디렉토리 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH7lRtSlpG7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "2b851201-50a6-49dc-ae3f-63b6e97199cd"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "original_dataset_dir = '/content/drive/MyDrive/plant-leaf-dataset/plant-leaf-dataset' #데이터셋이 위치한 경로 지정  \n",
        "classes_list = os.listdir(original_dataset_dir) #해당 경로 하위에 있는 모든 폴더의 목록을 가져옴(폴더 목록 == 클래스 목록)\n",
        " \n",
        "base_dir = '/content/drive/MyDrive/plant-leaf-dataset/plant-leaf-new-dataset' #train/val/test로 분할한 데이터를 저장할 폴더 생성\n",
        "os.mkdir(base_dir)\n",
        " \n",
        "train_dir = os.path.join(base_dir, 'train') #train 폴더 생성\n",
        "os.mkdir(train_dir)\n",
        "validation_dir = os.path.join(base_dir, 'val') #\bvalidation 폴더 생성\n",
        "os.mkdir(validation_dir)\n",
        "test_dir = os.path.join(base_dir, 'test') #test 폴더 생성\n",
        "os.mkdir(test_dir)\n",
        "\n",
        "for cls in classes_list: #train/val/test 폴더에 각각 클래스 목록 폴더를 생성    \n",
        "    os.mkdir(os.path.join(train_dir, cls))\n",
        "    os.mkdir(os.path.join(validation_dir, cls))\n",
        "    os.mkdir(os.path.join(test_dir, cls))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ff68ca51ce98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mbase_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/plant-leaf-dataset/plant-leaf-new-dataset'\u001b[0m \u001b[0;31m#train/val/test로 분할한 데이터를 저장할 폴더 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtrain_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#train 폴더 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/content/drive/MyDrive/plant-leaf-dataset/plant-leaf-new-dataset'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. train/validation/test 데이터 분할 및 클래스 별 데이터 수 확인"
      ],
      "metadata": {
        "id": "eKJ1QY2e28i4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_v0a0PUSrdnZ",
        "outputId": "de9a12b8-898d-490f-d6c7-f673b094921f"
      },
      "source": [
        "import math\n",
        "for cls in classes_list: #모든 클래스에 대한 작업 반복\n",
        "    path = os.path.join(original_dataset_dir, cls) \n",
        "    fnames = os.listdir(path) #path 위치에 존재하는 모든 이미지 파일의 목록을 fnames에 저장\n",
        "    \n",
        "    #train/validation/test 의 비율을 6:2:2로 (데이터 규모에 따라 조정 가능)\n",
        "    train_size = math.floor(len(fnames) * 0.6)\n",
        "    validation_size = math.floor(len(fnames) * 0.2)\n",
        "    test_size = math.floor(len(fnames) * 0.2)\n",
        "    \n",
        "    #train\n",
        "    train_fnames = fnames[:train_size] #train 데이터에 해당하는 파일의 이름을 train_fnames에 저장\n",
        "    for fname in train_fnames: #train 데이터에 대해 for문의 내용 반복\n",
        "        src = os.path.join(path, fname) #복사할 원본 파일의 경로 지정\n",
        "        dst = os.path.join(os.path.join(train_dir, cls), fname) #복사한 후 저장할 파일의 경로 지정\n",
        "        shutil.copyfile(src, dst) #src의 경로에 해당하는 파일을 dst의 경로에 지정\n",
        "    \n",
        "    #validation\n",
        "    validation_fnames = fnames[train_size:(validation_size + train_size)]\n",
        "    for fname in validation_fnames:\n",
        "        src = os.path.join(path, fname)\n",
        "        dst = os.path.join(os.path.join(validation_dir, cls), fname)\n",
        "        shutil.copyfile(src, dst)\n",
        "        \n",
        "    #test    \n",
        "    test_fnames = fnames[(train_size + validation_size):(test_size + validation_size + train_size)]\n",
        "    for fname in test_fnames:\n",
        "        src = os.path.join(path, fname)\n",
        "        dst = os.path.join(os.path.join(test_dir, cls), fname)\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "    print(\"class(\",cls,\") Train:\",len(train_fnames), \"Validation:\",len(validation_fnames), \"Test:\",len(test_fnames))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class( Apple___healthy ) Train: 987 Validation: 329 Test: 329\n",
            "class( Grape___healthy ) Train: 253 Validation: 84 Test: 84\n",
            "class( Grape___Black_rot ) Train: 708 Validation: 236 Test: 236\n",
            "class( Peach___Bacterial_spot ) Train: 1378 Validation: 459 Test: 459\n",
            "class( Potato___healthy ) Train: 91 Validation: 30 Test: 30\n",
            "class( Potato___Early_blight ) Train: 600 Validation: 200 Test: 200\n",
            "class( Corn___Common_rust ) Train: 715 Validation: 238 Test: 238\n",
            "class( Strawberry___Leaf_scorch ) Train: 671 Validation: 223 Test: 223\n",
            "class( Apple___Apple_scab ) Train: 378 Validation: 126 Test: 126\n",
            "class( Strawberry___healthy ) Train: 273 Validation: 91 Test: 91\n",
            "class( Peach___healthy ) Train: 216 Validation: 72 Test: 72\n",
            "class( Corn___healthy ) Train: 697 Validation: 232 Test: 232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYCY0sqFso7L"
      },
      "source": [
        "### 3. 기본 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucURIVBmsnmC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a0ca92a-8377-42d9-acac-c55647639ff2"
      },
      "source": [
        "import torch\n",
        "import os\n",
        " \n",
        "USE_CUDA = torch.cuda.is_available() #GPU 사용 가능한지 확인하는 메서드(사용할 수 있으면 TRUE, 없으면 FALSE 반환)\n",
        "print(USE_CUDA)\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\") #DEVICE 변수에 TRUE 이면 cuda를 FALSE 이면 cpu를 저장\n",
        "print(DEVICE)\n",
        "\n",
        "BATCH_SIZE = 32 #배치사이즈 지정\n",
        "EPOCH = 30 #에포크 지정\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "data_transforms = { # transforms.Compose()는 이미지 전처리, Augmentation 등 사용, Augmentation이란? 좌우 반전, 밝기 조절, 이미지 확대 등 노이즈를 주어 더 강한 모델을 만들어 주는 기법\n",
        "    'train': transforms.Compose([transforms.Resize([64,64]), # Resize -> 이미지의 크기를 64x64로 조정                    \n",
        "                                 transforms.RandomHorizontalFlip(), #RandomHorizontalFlip -> 이미지를 무작위로 좌우 반전\n",
        "                                 transforms.RandomVerticalFlip(), #RandomVerticalFlip -> 이미지를 무작위로 상하 반전\n",
        "                                 transforms.RandomCrop(52), #RandomCrop -> 이미지의 일부를 랜덤하게 잘라서 52x52 사이즈로 변경\n",
        "                                 transforms.ToTensor(), # ToTensor -> 이미지를 텐서 형태로 변환하고, 모든 값을 0~1 사이로 변경\n",
        "                                 transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ]), #Normalize ->정규화를 위해선 평균값과 표준편차값이 필요\n",
        "                                                                                                        #            첫번째[]는 R,G,B 채널 값에서 정규화를 적용할 평균값 \n",
        "                                                                                                        #            두번째[]는 R,G,B 채널 값에서 정규화를 적용할 표준편차값 \n",
        "                                                                                                        #            이 값은 이미지넷 데이터의 값이고, 정규화는 Local Minimum에 빠지는 것을 방지\n",
        "    'val': transforms.Compose([transforms.Resize([64,64]), \n",
        "                               #validation data는 Augmentation에 해당하는 부분을 제외하고 동일하게 전처리 \n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ])\n",
        "}"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. 데이터 로더"
      ],
      "metadata": {
        "id": "e0zmtPpS9oAW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STs5oRi2sy12",
        "outputId": "93bdc1fd-6cc5-4e28-d371-c65a5683eeae"
      },
      "source": [
        "from torchvision.datasets import ImageFolder #이미지 데이터는 하나의 클래스가 하나의 폴더에 대응되기 때문에 데이터셋을 불러올 때 ImageFolder를 사용\n",
        "\n",
        "# ImageFolder로 데이터셋 불러오기 -> root : 데이터 불러 올 경로 설정, transform : 앞서 설정한 전처리 방법 지정(불러오기 편하게 딕셔너리 형태로 구성)\n",
        "image_datasets = {x: ImageFolder(root=os.path.join(base_dir, x), transform=data_transforms[x]) for x in ['train', 'val']} \n",
        "\n",
        "# DataLoader로 불러온 이미지 데이터를 주어진 조건에 따라 미니 배치 단위로 분리 -> shuffle=True : 데이터의 순서가 섞여 학습시에 Label 정보의 순서를 기억하는 것을 방지 할 수 있음 필수!\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=4) for x in ['train', 'val']} \n",
        "\n",
        "#train/validation의 총 개수를 저장\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "\n",
        "#12개 클래스의 목록을 저장\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "print(class_names)\n",
        "print(len(class_names))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Apple___Apple_scab', 'Apple___healthy', 'Corn___Common_rust', 'Corn___healthy', 'Grape___Black_rot', 'Grape___healthy', 'Peach___Bacterial_spot', 'Peach___healthy', 'Potato___Early_blight', 'Potato___healthy', 'Strawberry___Leaf_scorch', 'Strawberry___healthy']\n",
            "12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. 전이학습 모델 불러오기\n",
        "1. 모델만 불러와서 구조 print 해보기\n",
        "2. 분류층 바꾸고 print 해보기"
      ],
      "metadata": {
        "id": "Uy5j3kc79q6x"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZEFZgmTs2Vt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7d1c55c13d764a54bb06ec156f069da3",
            "42f452642a63420b985fec7d997dc6b5",
            "57e72097660e4ce7bc5155076c6f87d2",
            "ebbbfe2a50c245d7a847588dc61ebb31",
            "bd5ef92b8eda45d0a042e4ba3977d06d",
            "d85879cdaaf447ab989fe5160a250603",
            "1ccafc879f2c4abebbbddd4f10916c54",
            "134433371d754024b1e7ebea9fd90947",
            "bd8272e7a2fb4e99873ed155d30300bc",
            "161814bfc38c41e584e055f3c0dd5356",
            "4b0d8f13656d400597bd65494faef33d"
          ]
        },
        "outputId": "6e74bc0e-541a-4424-c374-b107925bd7a6"
      },
      "source": [
        "from torchvision import models #pytorch 공식문서에서 확인 한 것처럼, 여기서 여러 모델을 불러올 수 있음\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "'''\n",
        "#resnet18/34/50 \n",
        "model = models.resnet50(pretrained=True) #pretrained=True로 설정하면 pre-trained model의 parameter값을 그대로 가져옴, False로 설정하면 모델의 아키텍처만 가져오고 parameter는 랜덤 설정\n",
        "num_ftrs = model.fc.in_features #모델의 마지막 레이어의 입력 채널의 수를 저장(in_features는 해당 레이어의 입력 채널 수를 의미)   \n",
        "model.fc = nn.Linear(num_ftrs, len(class_names)) #모델의 마지막 레이어를 새로운 레이어로 교체 (입력 채널 수는 기존 레이어와 동일, 출력 채널 수를 우리가 원하는 수로 설정하는 것! 여기서는 클래스 수 12개) \n",
        "\n",
        "\n",
        "#vgg16/19\n",
        "model = models.vgg16(pretrained=True)\n",
        "model.classifier[6].out_features = len(class_names) #마지막 레이어를 교체하는 방법이 약간 다름, print 해서 구조 확인하면서 이해\n",
        "\n",
        "#mobilenet_v2\n",
        "model = models.mobilenet_v2(pretrained=True)\n",
        "#model.classifier[1].out_features = len(class_names)\n",
        "\n",
        "#mobilnet_v3_small\n",
        "model = models.mobilenet_v3_small(pretrained=True)\n",
        "#model.classifier[3].out_features = len(class_names)\n",
        "'''\n",
        "#googlenet\n",
        "model = models.googlenet(pretrained=True)\n",
        "\n",
        "model = model.to(DEVICE) #모델 gpu에 태우기\n",
        "print(model)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /root/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d1c55c13d764a54bb06ec156f069da3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/49.7M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GoogLeNet(\n",
            "  (conv1): BasicConv2d(\n",
            "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  (conv2): BasicConv2d(\n",
            "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv3): BasicConv2d(\n",
            "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  (inception3a): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception3b): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  (inception4a): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception4b): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception4c): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception4d): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception4e): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  (inception5a): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception5b): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (aux1): None\n",
            "  (aux2): None\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (fc): Linear(in_features=1024, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Layer Freeze"
      ],
      "metadata": {
        "id": "4zzyFflRf13T"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wf8IIPgs3vs"
      },
      "source": [
        "cnt = 0 #몇 번째 Layer인지 나타내는 변수 cnt 설정\n",
        "for child in model.children(): #모델의 모든 Layer 정보를 담고 있음 (vgg, mobilenet 계열은 model.features)\n",
        "    cnt += 1 \n",
        "    #import pdb;pdb.set_trace() #디버거 cnt,n,c,child,q\n",
        "    if cnt < 8: #resnet50기준 10개의 Layer중 1~5개는 Freeze하고, 6~10은 학습 시 parameter를 업데이트 하도록!\n",
        "        #print(child)\n",
        "        for param in child.parameters(): #vgg, mobilenet 계열은 model.features.parameters()\n",
        "            param.requires_grad = False  #False -> NO UPDATE(FREEZE), True -> UPDATE(기본값)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. 손실함수, 최적화함수, 스케쥴러 설정\n",
        "- Adam vs SGD\n",
        "- learning rate는 작게!\n",
        "- 미리 학습 코드까지 실행!"
      ],
      "metadata": {
        "id": "onKCFqbZf9oZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 학습에 사용하는 Loss 함수를 지정\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#Optimizer는 Adam, filter와 lambda를 사용하는 이유 : param.requires_grad = True로 설정된 Layer의 parameter만을 업데이트 하기 위해서!\n",
        "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.00001) #전이학습 시에는 lr 낮게(과적합 방지)\n",
        " \n",
        "from torch.optim import lr_scheduler\n",
        "# 에포크에 따라 Learning Rate를 변경하는 역할 (7 에포크마다 0.1씩 곱해 LR을 감소시킴), Why? : 학습 보폭을 정하는 일은 매우 중요한데, 처음엔 크게 -> 학습 진행될 수록 작게 설정하는 것이 좋다고 알려짐, but 아직 연구중\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "LfwDUXcaD_uD"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. 모델 학습 및 저장"
      ],
      "metadata": {
        "id": "t86IqtKnK8Qr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXFjVMs3s5Jv"
      },
      "source": [
        "# 전이학습 모델 학습 및 검증\n",
        "import time\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n",
        "    \n",
        "    train_losses , train_accuracy = [],[] #그래프 그리기 위해서 train에 대한 loss,accuracy 저장\n",
        "    val_losses , val_accuracy = [],[] #그래프 그리기 위해서 validation에 대한 loss,accuracy 저장\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())  #정확도가 가장 높은 모델을 저장\n",
        "    best_acc = 0.0 #정확도가 가장 높은 모델의 정확도 저장\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print('-------------- epoch {} ----------------'.format(epoch+1)) \n",
        "        since = time.time() #한 에포크 돌 때 소요되는 시간 측정(시작 시각 저장)                                    \n",
        "        for phase in ['train', 'val']: #한 에포크 돌 때 train 한 번, validation 한 번씩 각각 진행\n",
        "            if phase == 'train': \n",
        "                model.train() #train이면 학습 모드\n",
        "            else:\n",
        "                model.eval() #validation이면 평가 모드(평가 때 사용하지 말아야 할 작업들 알아서 꺼줌, dropout이나 batchnorm layer 같은 것들)     \n",
        " \n",
        "            running_loss = 0.0   #모든 데이터의 loss를 합해서 저장\n",
        "            running_corrects = 0 #정확하게 예측한 경우의 수를 저장\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]: #모델의 현재 모드(train or validation)에 해당하는 Dataloader에서 데이터를 받는 for문\n",
        "                inputs = inputs.to(DEVICE) #데이터를 gpu에 태움 \n",
        "                labels = labels.to(DEVICE) #데이터의 라벨값을 gpu에 태움\n",
        "                \n",
        "                optimizer.zero_grad() #학습 진행하면 이전 Batch의 Gradient값이 Optimizer에 저장될 것이므로 초기화 해주고 시작해야 함\n",
        "                \n",
        "                with torch.set_grad_enabled(phase == 'train'): #set_grad_enabled를 이용하면 train 모드에서만 모델의 Gradient를 업데이트 하도록 설정 할 수 있음\n",
        "                    outputs = model(inputs) #드디어 데이터를 모델에 입력!\n",
        "                    _, preds = torch.max(outputs, 1) #모델에 입력된 데이터가 12개의 클래스에 속할 확률값 출력, 이 중 가장 높은 값의 인덱스를 예측값으로 preds에 저장\n",
        "                    loss = criterion(outputs, labels) #모델의 예측값과 정답값 사이의 Loss를 계산(criterion 함수는 위에서 미리 설정해 둔 것)\n",
        "    \n",
        "                    if phase == 'train':   \n",
        "                        loss.backward() #계산한 loss값을 이용하여 BackPropagation을 통해 계산한 Gradient값을 parameter에 할당하고,\n",
        "                        optimizer.step() #모델의 parameter 업데이트\n",
        " \n",
        "                running_loss += loss.item() * inputs.size(0) #모든 데이터의 loss를 합해서 저장하기 위해, 하나의 미니 배치에 대한 loss값에 데이터의 수를 곱해서 더함 (inputs.size(0)이 미니 배치의 수) \n",
        "                running_corrects += torch.sum(preds == labels.data) #예측값과 정답값이 같으면 증가!\n",
        "\n",
        "            if phase == 'train':  \n",
        "                scheduler.step() #위에서 미리 설정한 Scheduler 실행\n",
        " \n",
        "            epoch_loss = running_loss/dataset_sizes[phase] #해당 에포크의 loss를 계산하기 위해 running_loss를 데이터셋 사이즈로 나눔\n",
        "            epoch_acc = running_corrects.double()/dataset_sizes[phase] #정확도도 마찬가지로 running_corrects를 데이터셋 사이즈로 나눔\n",
        " \n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc)) #해당 에포크의 loss와 정확도를 매번 출력\n",
        "\n",
        "            if phase == 'train': #그래프 그리기 위해 train 데이터의 loss와 accuracy 따로 저장\n",
        "                train_losses.append(epoch_loss)\n",
        "                train_accuracy.append(epoch_acc)\n",
        "            if phase == 'val': #그래프 그리기 위해 \bvalidation 데이터의 loss와 accuracy 따로 저장\n",
        "                val_losses.append(epoch_loss)\n",
        "                val_accuracy.append(epoch_acc)\n",
        "          \n",
        "            if phase == 'val' and epoch_acc > best_acc: #validation 모드에서 정확도가 최고 정확도 보다 높으면 업데이트\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict()) #최고 정확도를 가진 모델을 best_model_wts 변수에 저장\n",
        " \n",
        "        time_elapsed = time.time() - since #한 에포크 돌 때 소요되는 시간 측정(종료 시각 - 시작 시각) \n",
        "        print('Completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)) #계산한 시간 분과 초로 출력\n",
        "\n",
        "    #학습 종료 후 \n",
        "    print('Best validation Acc: {:4f}'.format(best_acc)) #validation 중 최고 정확도 출력\n",
        "\n",
        "    #train과 validation의 loss, accuracy 그래프 출력 -> 과적합 여부 등 판단\n",
        "    plt.plot(range(1,len(train_losses)+1),train_losses,'bo',label = 'training loss')\n",
        "    plt.plot(range(1,len(val_losses)+1),val_losses,'r',label = 'validation loss')\n",
        "    plt.legend()\n",
        "    plt.plot(range(1,len(train_accuracy)+1),train_accuracy,'co',label = 'training accuracy')\n",
        "    plt.plot(range(1,len(val_accuracy)+1),val_accuracy,'m',label = 'validation accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    #정확도가 가장 높았던 모델을 불러와서 반환\n",
        "    model.load_state_dict(best_model_wts) \n",
        "    return model"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "id": "EQ6wBtMAs6pw",
        "outputId": "93037562-926c-49b1-b60d-1d83409feb91"
      },
      "source": [
        "# 전이학습 실행\n",
        "model = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=EPOCH) \n",
        "\n",
        "# 반환 받은 정확도가 가장 높았던 모델을 torch.save 이용해서 저장 (모델 별로 이름 변경해서 저장!)\n",
        "torch.save(model, '/content/drive/MyDrive/plant-leaf-dataset/vgg16.pt')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------- epoch 1 ----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 13.7567 Acc: 0.0030\n",
            "val Loss: 8.0425 Acc: 0.0125\n",
            "Completed in 0m 21s\n",
            "-------------- epoch 2 ----------------\n",
            "train Loss: 7.5237 Acc: 0.0353\n",
            "val Loss: 5.2567 Acc: 0.1177\n",
            "Completed in 0m 21s\n",
            "-------------- epoch 3 ----------------\n",
            "train Loss: 5.1374 Acc: 0.1387\n",
            "val Loss: 3.9447 Acc: 0.2716\n",
            "Completed in 0m 21s\n",
            "-------------- epoch 4 ----------------\n",
            "train Loss: 3.8237 Acc: 0.2657\n",
            "val Loss: 2.9303 Acc: 0.4284\n",
            "Completed in 0m 21s\n",
            "-------------- epoch 5 ----------------\n",
            "train Loss: 2.9861 Acc: 0.3860\n",
            "val Loss: 2.2385 Acc: 0.5185\n",
            "Completed in 0m 21s\n",
            "Best validation Acc: 0.518534\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhU5fn/8fedhcSwRkDKmoAiSzYSIqCRrYCitigoYgsqFspV6lK//rRSbUXtF6stRb5Y1KKVKqYKomhdqEoNoBWVsMqmVMImCgEhAoGQkPv3x8lMtkkyM5lkMsn9uq65MnPOmTn3HODDk+ec5zmiqhhjjAk9YcEuwBhjjH8swI0xJkRZgBtjTIiyADfGmBBlAW6MMSEqoj531q5dO42Pj6/PXRpjTMhbt27dYVVtX3F5vQZ4fHw82dnZ9blLY4wJeSKyx9Ny60IxxpgQZQFujDEhqsYAF5HnROSQiGzxsO7/iYiKSLu6Kc8YY0xVvOkD/zvwF+CFsgtFpCtwGbA38GUZ0/gVFhayf/9+Tp8+HexSTAMRHR1Nly5diIyM9Gr7GgNcVVeLSLyHVY8Dvwbe8KVAY4xj//79tGzZkvj4eEQk2OWYIFNVjhw5wv79++nevbtX7/GrD1xErga+VtVNXmw7TUSyRSQ7NzfX531lZkJ8PISFOT8zM32v15iG6PTp07Rt29bC2wAgIrRt29an38h8voxQRGKA+3C6T2qkqguABQDp6ek+TX2YmQnTpkF+vvN6zx7nNcDEib58kjENk4W3KcvXvw/+tMDPB7oDm0RkN9AFWC8iP/Djs6p1//2l4e2Sn+8sN8aYps7nAFfVz1X1PFWNV9V4YD+QpqrfBrq4vVWcHq1quTHGe8eOHePJJ5/0671XXnklx44dq3abBx54gBUrVvj1+RXFx8dz+PDhgHxWY+LNZYQvAWuAXiKyX0Sm1H1Zjm7dfFtuTGMW6PNB1QV4UVFRte995513aNOmTbXbPPzww4wcOdLv+kzNagxwVf2JqnZU1UhV7aKqf6uwPl5V6+S/xlmzICam/LKYGGe5MU2J63zQnj2gWno+qDYhPmPGDL766iv69evHPffcw8qVKxk8eDBjxoyhb9++AFxzzTX079+fhIQEFixY4H6vq0W8e/du+vTpw89//nMSEhK47LLLOHXqFACTJ09m6dKl7u1nzpxJWloaSUlJ7NixA4Dc3FxGjRpFQkICU6dOJS4ursaW9pw5c0hMTCQxMZG5c+cCcPLkSa666ipSUlJITExk8eLF7u/Yt29fkpOTufvuu/0/WA2Vqtbbo3///uqrF19UjYtTFXF+vviizx9hTIO0bds2r7eNi1N1orv8Iy7O//3n5ORoQkKC+3VWVpbGxMTorl273MuOHDmiqqr5+fmakJCghw8fLqknTnNzczUnJ0fDw8N1w4YNqqo6fvx4XbRokaqq3nzzzfrKK6+4t583b56qqs6fP1+nTJmiqqq33nqrPvLII6qqunz5cgU0NzfXw/d39pedna2JiYl64sQJPX78uPbt21fXr1+vS5cu1alTp7q3P3bsmB4+fFgvvPBCLS4uVlXVo0eP+n+w6pGnvxdAtnrI1AY/lH7iRNi9G4qLnZ929YlpiurrfNCAAQPKXYM8b948UlJSGDRoEPv27WPnzp2V3tO9e3f69esHQP/+/dm9e7fHzx43blylbT766CNuuOEGAEaPHk1sbGy19X300UeMHTuW5s2b06JFC8aNG8eHH35IUlIS77//Pvfeey8ffvghrVu3pnXr1kRHRzNlyhRee+01Yir+Ot8INPgAN8bU3/mg5s2bu5+vXLmSFStWsGbNGjZt2kRqaqrHa5SjoqLcz8PDw6vsP3dtV902/rrwwgtZv349SUlJ/Pa3v+Xhhx8mIiKCzz77jOuuu4633nqL0aNHB3SfDYEFuDEhoC7OB7Vs2ZLjx49XuT4vL4/Y2FhiYmLYsWMHn3zyif87q0JGRgZLliwB4L333uPo0aPVbj948GBef/118vPzOXnyJMuWLWPw4MEcOHCAmJgYJk2axD333MP69es5ceIEeXl5XHnllTz++ONs2lTjuMOQU6/zgRtj/OPqOrz/fqfbpFs3J7xr06XYtm1bMjIySExM5IorruCqq64qt3706NE8/fTT9OnTh169ejFo0KBafAPPZs6cyU9+8hMWLVrExRdfzA9+8ANatmxZ5fZpaWlMnjyZAQMGADB16lRSU1N59913ueeeewgLCyMyMpKnnnqK48ePc/XVV3P69GlUlTlz5gS8/mATp3+8fqSnp6vd0MEYx/bt2+nTp0+wywiqgoICwsPDiYiIYM2aNUyfPp2NGzcGu6yg8vT3QkTWqWp6xW2tBW6MCZq9e/dy/fXXU1xcTLNmzXjmmWeCXVJIsQA3xgRNz5492bBhQ7DLCFl2EtMYY0KUBbgxxoQoC3BjjAlRFuDGGBOiLMCNMV5r0aIFAAcOHOC6667zuM2wYcOo6XLhuXPnkl9msn9vpqf1xoMPPsjs2bNr/TmhwgLcGOOzTp06uWca9EfFAPdmelpTmQW4MU3UjBkzmD9/vvu1q/V64sQJRowY4Z769Y03Kt+3fPfu3SQmJgJw6tQpbrjhBvr06cPYsWPd08kCTJ8+nfT0dBISEpg5cybgTJB14MABhg8fzvDhw4HyN2zwNF1sddPWVmXjxo0MGjSI5ORkxo4d6x6mP2/ePPcUs66JtFatWkW/fv3o168fqamp1U4x0JDYdeDGNAR33gmBHoHYrx+UBKAnEyZM4M477+TWW28FYMmSJbz77rtER0ezbNkyWrVqxeHDhxk0aBBjxoyp8n6NTz31FDExMWzfvp3NmzeTlpbmXjdr1izOPfdczp49y4gRI9i8eTN33HEHc+bMISsri3bt2pX7rHXr1rFw4UI+/fRTVJWBAwcydOhQYmNj2blzJy+99BLPPPMM119/Pa+++iqTJk2q8vvddNNNPPHEEwwdOpQHHniAhx56iLlz5/Loo4+Sk5NDVFSUu9tm9uzZzJ8/n4yMDE6cOEF0dLTXhzmYrAVuTBOVmprKoUOHOHDgAJs2bSI2NpauXbuiqtx3330kJyczcuRIvv76aw4ePFjl56xevdodpMnJySQnJ7vXLVmyhLS0NFJTU9m6dSvbtm2rtqaqposF76etBWcirmPHjjF06FAAbr75ZlavXu2uceLEibz44otERDht2IyMDO666y7mzZvHsWPH3MsbutCo0pjGrpqWcl0aP348S5cu5dtvv2XChAkAZGZmkpuby7p164iMjCQ+Pt7jNLI1ycnJYfbs2axdu5bY2FgmT57s1+e4VJy2tqYulKq8/fbbrF69mjfffJNZs2bx+eefM2PGDK666ireeecdMjIyePfdd+ndu7fftdYXa4Eb04RNmDCBl19+maVLlzJ+/HjAab2ed955REZGkpWVxZ49e6r9jCFDhvCPf/wDgC1btrB582YAvv/+e5o3b07r1q05ePAgy5cvd7+nqqlsq5ou1letW7cmNjbW3XpftGgRQ4cOpbi4mH379jF8+HAee+wx8vLyOHHiBF999RVJSUnce++9XHTRRe5bvjV0NbbAReQ54EfAIVVNLFn2J+DHwBngK+AWVa39NUDGmHqVkJDA8ePH6dy5Mx07dgRg4sSJ/PjHPyYpKYn09PQaW6LTp0/nlltuoU+fPvTp04f+/fsDkJKSQmpqKr1796Zr165kZGS43zNt2jRGjx5Np06dyMrKci+varrY6rpLqvL888/zi1/8gvz8fHr06MHChQs5e/YskyZNIi8vD1XljjvuoE2bNvzud78jKyuLsLAwEhISuOKKK3zeXzDUOJ2siAwBTgAvlAnwy4APVLVIRB4DUNV7a9qZTSdrTCmbTtZ44st0st7clX418F2FZe+pquueSJ8AXfwv1xhjjD8C0Qf+M2B5VStFZJqIZItIdm5ubgB2Z4wxBmoZ4CJyP1AEZFa1jaouUNV0VU1v3759bXZnjDGmDL8vIxSRyTgnN0dofd6XzRhjDOBngIvIaODXwFBVza9pe2OMMYFXYxeKiLwErAF6ich+EZkC/AVoCbwvIhtF5Ok6rtMYY0wF3lyF8hNV7aiqkaraRVX/pqoXqGpXVe1X8vhFfRRrjAmcY8eO8eSTT/r1Xm+mf33ggQdYsWKFX59vvGMjMY0JEZkHDxK/Zg1hK1cSv2YNmdXMT+KN6gK8qKjI43IXb6Z/ffjhhxk5cqTf9QVDTd+7obEANyYEZB48yLQvvmBPQQEK7CkoYNoXX9QqxGfMmMFXX31Fv379uOeee1i5ciWDBw9mzJgx9O3bF4BrrrmG/v37k5CQwIIFC9zvdU3/Wt00r5MnT3bPGR4fH8/MmTPdU9S6hqrn5uYyatQoEhISmDp1KnFxce5pZcvyNC0twNq1a7nkkktISUlhwIABHD9+nLNnz3L33XeTmJhIcnIyTzzxRLmaAbKzsxk2bBjgTKN74403kpGRwY033sju3bsZPHgwaWlppKWl8fHHH7v399hjj5GUlERKSor7+JWdfXHnzp3lXtc5Va23R//+/dUY49i2bZvX28Z9/LGSlVXpEffxx37vPycnRxMSEtyvs7KyNCYmRnft2uVeduTIEVVVzc/P14SEBD18+LBTT1yc5ubmak5OjoaHh+uGDRtUVXX8+PG6aNEiVVW9+eab9ZVXXnFvP2/ePFVVnT9/vk6ZMkVVVW+99VZ95JFHVFV1+fLlCmhubm6lWl11FBUV6dChQ3XTpk1aUFCg3bt3188++0xVVfPy8rSwsFCffPJJvfbaa7WwsLDce101q6quXbtWhw4dqqqqM2fO1LS0NM3Pz1dV1ZMnT+qpU6dUVfXLL79UV2698847evHFF+vJkyfLfe6wYcPc3/83v/mN+3v6y9PfCyBbPWSqzUZoTAjYW1Dg03J/DRgwgO7du7tfz5s3j2XLlgGwb98+du7cSdu2bcu9x9tpXseNG+fe5rXXXgOc6WNdnz969GhiY2M9vnfJkiUsWLCAoqIivvnmG7Zt24aI0LFjRy666CIAWrVqBcCKFSv4xS9+4Z4S9txzz63xe48ZM4ZzzjkHgMLCQm677TY2btxIeHg4X375pftzb7nlFmJiYsp97tSpU1m4cCFz5sxh8eLFfPbZZzXuL1AswI0JAd2iotjjIay7lZliNRCaN2/ufr5y5UpWrFjBmjVriImJYdiwYR6ng/V2mlfXduHh4T71NQdqWtqIiAiKi4sBKr2/7Pd+/PHH6dChA5s2baK4uLjGmztce+21PPTQQ/zwhz+kf//+lf6Dq0vWB25MCJjVowcxYeX/ucaEhTGrRw+/P7OqKV1d8vLyiI2NJSYmhh07dvDJJ5/4va+qZGRksGTJEgDee+89923PyqpqWtpevXrxzTffsHbtWgCOHz9OUVERo0aN4q9//av7P4nvvnOmcoqPj2fdunUAvPrqq1XWlJeXR8eOHQkLC2PRokWcPXsWgFGjRrFw4UL3vTxdnxsdHc3ll1/unpWxPlmAGxMCJnbowIJevYiLikKAuKgoFvTqxcQOHfz+zLZt25KRkUFiYiL33HNPpfWjR4+mqKiIPn36MGPGDAYNGlSLb+DZzJkzee+990hMTOSVV17hBz/4AS1btiy3TdlpaX/605+6p6Vt1qwZixcv5vbbbyclJYVRo0Zx+vRppk6dSrdu3UhOTiYlJcU9V/nMmTP51a9+RXp6OuHh4VXW9Mtf/pLnn3+elJQUduzY4W6djx49mjFjxpCenk6/fv2YPXu2+z0TJ04kLCyMyy67LNCHqFo1TicbSDadrDGlbDpZKCgoIDw8nIiICNasWcP06dPZGOh7g9aD2bNnk5eXx+9///taf5Yv08laH7gxJmj27t3L9ddfT3FxMc2aNeOZZ54Jdkk+Gzt2LF999RUffPBBve/bAtwYEzQ9e/Zkw4YNwS6jVlxX0QSD9YEbY0yIsgA3xpgQZQFujDEhygLcGGNClAW4McZrLVq0AODAgQNcd911HrcZNmwYNV0uPHfuXPeAGPBuelpTmQW4McZnnTp1cs806I+KAe7N9LQNiaq6h+UHkwW4MU3UjBkzmD9/vvv1gw8+yOzZszlx4gQjRoxwT/36xhtvVHrv7t27SUxMBODUqVPccMMN9OnTh7Fjx5abC8XTNLDz5s3jwIEDDB8+nOHDhwPlp3qdM2cOiYmJJCYmMnfuXPf+qpq2tqw333yTgQMHkpqaysiRIzlYMt3uiRMnuOWWW0hKSiI5Odk9lP5f//oXaWlppKSkMGLEiHLHwSUxMZHdu3eze/duevXqxU033URiYiL79u3zaZrbIUOGlBukdOmll7Jp0yav/7w8sevAjWkAdt65kxMbTwT0M1v0a0HPuT2rXD9hwgTuvPNObr31VsCZ8e/dd98lOjqaZcuW0apVKw4fPsygQYMYM2YMIuLxc5566iliYmLYvn07mzdvLjcf9qxZszj33HM5e/YsI0aMYPPmzdxxxx3MmTOHrKws2rVrV+6z1q1bx8KFC/n0009RVQYOHMjQoUOJjY1l586dvPTSSzzzzDNcf/31vPrqq0yaNKnc+y+99FI++eQTRIRnn32WP/7xj/z5z3/m97//Pa1bt+bzzz8H4OjRo+Tm5vLzn/+c1atX0717d/fcJtXZuXMnzz//vHtaAU/fr3fv3kyYMIHFixdz0UUX8f3333POOecwZcoU/v73vzN37ly+/PJLTp8+TUpKSo37rI61wI1polJTUzl06BAHDhxg06ZNxMbG0rVrV1SV++67j+TkZEaOHMnXX3/tbsl6snr1aneQJicnk5yc7F63ZMkS0tLSSE1NZevWrWzbtq3amj766CPGjh1L8+bNadGiBePGjePDDz8EvJu2dv/+/Vx++eUkJSXxpz/9ia1btwLOVLCu/6gAYmNj+eSTTxgyZIh7+lxvpp2Ni4srNyeMp+/3xRdfVJrmNiIigvHjx/PWW29RWFjIc889x+TJk2vcX02sBW5MA1BdS7kujR8/nqVLl/Ltt98yYcIEADIzM8nNzWXdunVERkYSHx/v1/StgZoG1sWbaWtvv/127rrrLsaMGcPKlSt58MEHfd5P2WlnofzUs2WnnfX1+8XExDBq1CjeeOMNlixZ4p4ZsTa8uSv9cyJySES2lFl2roi8LyI7S356noXdGNOgTZgwgZdffpmlS5cyfvx4wJlO9bzzziMyMpKsrCz27NlT7WcMGTLEPePfli1b2Lx5M1D1NLBQ9VS2gwcP5vXXXyc/P5+TJ0+ybNkyBg8e7PX3ycvLo3PnzgA8//zz7uWjRo0q199/9OhRBg0axOrVq8nJyQHKTzu7fv16ANavX+9eX5Gv09yCc/OHO+64g4suuqjKm1f4wpsulL8DoyssmwH8W1V7Av8ueW2MCTEJCQkcP36czp0707FjR8CZGjU7O5ukpCReeOEFevfuXe1nTJ8+nRMnTtCnTx8eeOAB+vfvD1Q9DSzAtGnTGD16tPskpktaWhqTJ09mwIABDBw4kKlTp5Kamur193nwwQcZP348/fv3L9e//tvf/pajR4+SmJhISkoKWVlZtG/fngULFjBu3DhSUlLcv4Fce+21fPfddyQkJPCXv/yFCy+80OO+fJ3mFpyun1atWgVs3nCvppMVkXjgLVVNLHn9BTBMVb8RkY7ASlXtVdPn2HSyxpSy6WSbngMHDjBs2DB27NhBWJjn9rMv08n6exKzg6p+U/L8W6DKWeVFZJqIZItIdm5urp+7M8aY0PbCCy8wcOBAZs2aVWV4+6rWn1Jyx+Qqm/GqukBV01U1vX379rXdnTHGhKSbbrqJffv2uc81BIK/AX6wpOuEkp+HAlaRMU1Ifd4RyzR8vv598DfA/wncXPL8ZqDyUC1jTLWio6M5cuSIhbgBnPA+cuQI0dHRXr+nxuvAReQlYBjQTkT2AzOBR4ElIjIF2ANc71fFxjRhXbp0Yf/+/di5IeMSHR1Nly5dvN6+xgBX1Z9UsWqE13sxxlQSGRnpHgVojD9sKL0xxoQoC3BjjAlRFuDGGBOiLMCNMSZEWYAbY0yIsgA3xpgQZQFujDEhygLcGGNClAW4McaEKAtwY4wJURbgxhgToizAjTEmRFmAG2NMiLIAN8aYEGUBbowxIcoC3BhjQpQFuDHGhCgLcGOMCVEW4MYYE6IswI0xJkTVKsBF5H9EZKuIbBGRl0QkOlCFGWOMqZ7fAS4inYE7gHRVTQTCgRsCVVg569bBG2+Aap18vDHGhKLadqFEAOeISAQQAxyofUkezJsH11wDl1wCWVl1sgtjjAk1fge4qn4NzAb2At8Aear6XsXtRGSaiGSLSHZubq5/O3v2WXjmGdi/H374Qxg1Ctau9bd0Y4xpFGrThRILXA10BzoBzUVkUsXtVHWBqqaranr79u3921lkJEydCjt3wp//DBs2wIABcO21sH27v1/BGGNCWm26UEYCOaqaq6qFwGvAJYEpqwrR0XDXXbBrFzz4ILz/PiQmwuTJsHt3ne7aGGMamtoE+F5gkIjEiIgAI4D6aQ63agUzZzpB/j//Ay+/DBdeCHfcAQcP1ksJxhgTbLXpA/8UWAqsBz4v+awFAarLO+3awezZ8N//Oq3wJ5+EHj3g/vvh2LF6LaWhyMyE+HgIC3N+ZmYGuyJjTF0RrcdL89LT0zU7O7vudrBzJzzwgNMij42Fe++F22+HmJi622cDkpkJ06ZBfn7pspgYWLAAJk4MXl3GmNoRkXWqml5xeeMaidmzJ7z0knOS8+KLYcYMOP98p2V+5kywq6tz999fPrzBeX3//cGpxxhTtxpXgLv06wdvvw0ffuiE+q23Qu/esGgRnD0b7OrqzN69vi03xoS2xhngLpdeCqtWwTvvQOvWcNNNTrg30lGd3br5ttwYE9oad4ADiMAVVzjD8RcvdrpSrrnG6WL54INgVxdQs2ZV7u6PiXGWG2Man8Yf4C5hYXD99bB1qzOy8+uvYcSIRjWqc+JE54RlXJzz/1ZcnJ3ANKYxa1xXofji9Gl46il45BE4fBjGjoX//V/o2zfYlRljTDlN4yoUX0RHO4OAdu2Chx6CFSsgKclGdRpjQkbTDXCXli2da8crjuq8/XYb1WmMadAswF3Kjuq85Rane6WJj+o0xjRsFuAVdekCf/2rM8vh1Vc7feTdu8Ojj1YeJWOMMUFkAV6Vnj3hH/+AjRshIwN+85smNarTGNPwWYDXJCUF3nqryY3qNMY0fBbg3nKN6ly+HNq0cUZ1pqQ02lGdxpiGzwLcFyIwejRkZ8OSJVBY2GhHdRpjGj4LcH+EhcH48Y16VKcxpuGzAK+NiAiYMsWZh/zxx50TngMGwLhxsG1bsKszxjRyFuCBEB0Nd95ZeVTnzTfbqE5jTJ2xAA+ksqM677rL6Sd3jer89ttgV2eMaWQswOtCu3bwpz+VH9V5/vlw3302qtMYEzAW4HWpc2dnVOeOHc6ozj/8oXRU58mTwa7OGBPiahXgItJGRJaKyA4R2S4iFweqsEblggtKR3VeeqkzqvOCC2D+fBvVaYzxW21b4P8H/EtVewMpwPbal9SIpaTAm2/CRx85feO33WajOo0xfvM7wEWkNTAE+BuAqp5RVevg9UZGBqxcCf/6F8TGlo7qfP11G9VpjPFabVrg3YFcYKGIbBCRZ0WkecWNRGSaiGSLSHZubm4tdtfIiMDllzsDf5YsgaIi565ANqrTGOOl2gR4BJAGPKWqqcBJYEbFjVR1gaqmq2p6+/bta7G7Rso1qnPLFvjb3+DAAWdU58iR8Nlnwa7OGNOA1SbA9wP7VfXTktdLcQLd+CMiAn72M/jyS2dU56ZNMHCgM6pz69ZgV2eMaYD8DnBV/RbYJyK9ShaNAGz8eG2VHdX58MPw73/bqE5jjEe1vQrldiBTRDYD/YBHal+SAZxRnb/7nRPkd99tozqNMZXUKsBVdWNJ/3ayql6jqkcDVZgp0bYt/PGPzqjOn/0Mnn66dFTnUTvcxjRlNhIzVHTu7IT39u3OHOSPPurcdPkPf7BRncY0URbgoeaCCyAzs3RU5333OS1yG9VpTJNjAR6qkpOdUZ3/+Y8zmvO226BXL3jhBRvVaUwTYQEe6i65BLKynFGd557rXK2SkgIvv2x95F7IzIT4eOdy/Ph457UxocICvDFwjerMzoZXXnFGdf7kJ84J0NRU57LEZcvgyJFgV9qgZGbCtGmwZ48zg8GePc5rC3ETKkTrce6N9PR0zc7Orrf9NVlFRfDxx7BqlTPnypo1cOqUsy4pCYYNg6FDYcgQaMKjY+PjndCuKC7OLrk3DYuIrFPV9ErLLcCbgIICZ86VVaucx3/+A/n5zrqEBCfMhw1zAr1Dh6CWWp/CwjzPHSYCxcX1X48xVbEAN6XOnIF165zW+apVzvS2rksR+/RxAt316NgxqKXWJWuBm1BhAW6qVlgI69eXdrl89BEcP+6su/DC0i6XoUOd69EbCVcfuOuXEYCYGFiwACZODF5dxlRkAW68V1QEGzaUdrmsXg3ff++su+CC8oHetWtQS62tzEy4/37Yuxe6dYNZsyy8TcNjAW78d/asMzuiq8tl9erSmzP36FHahz50qNP/YIwJKAtwEzhnz8Lnn5cP9O++c9bFx5cP9Ph456ygMcZvFuCm7hQXOzekcPWhr14Nhw8767p2LQ3zYcOcFrsFujE+sQA39ae4GLZtKw30VavAdTu9zp3L96H37GmBbkwNLMBN8KjCjh2lYb5yJRw86Kzr2LF8l0uvXhboxlRgAW4aDlXn1nGuQF+1yrkXKDgDiVyt82HDnOvSLdBNE2cBbhouVeeGFWW7XPbvd9a1b18+0Pv2dYZQGtOEWICb0KEKOTnlu1z27nXWtW3rDPl3dbkkJVmgm0bPAtyEtt27ywe6a6z7uefC4MGlgZ6cDOHhQSvTmLpQZwEuIuFANvC1qv6oum0twE3A7N1bvsvlq6+c5W3aOIHu6nLp188C3YS8qgI8IgCf/StgO9AqAJ9ljHe6dYMbb3Qe4PSZlw30N990lrdqVRroQ4dCWhpEBOKvvTHBV6u/ySLSBbgKmAXcFWFuk1cAAA66SURBVJCKjPFHly7OJCauiUwOHCi9wmXlSnj7bWd5y5aQkVHa5dK/P0RGBqtqY2qltmd/5gK/BqqcPVlEpolItohk57oGcxhT1zp1cu5K9PTTzjXo33zj3GZu0iRnDtkZM+DiiyE21rmb0axZzm3pXNenG4/sFnQNi9994CLyI+BKVf2liAwD7rY+cBMyDh1yhvy7uly2bCld17Gjcyu6so/u3Zv89eg2/W7wBPwkpoj8AbgRKAKicfrAX1PVSVW9xwLcNFjHjjkzLm7Y4MyNvmEDbN/uTNwF0Lq1c0K0bKj36dOk+tPtBhjBU6eXEVoL3DRKp045LfMNG0ofmzeX3l80Ksq5Dj0trTTUk5KcZmkjZLegC566vArFmMbpnHPgoouch0tRkTMNQNlQf+UVpx8BnJTr3btyF0xsbHC+QwB16+a5Bd6tW/3XYhw2kMeY2lJ1rksv2/2yYQN8/XXpNnFxlUO9c+eQ6le3PvDgsRa4MXVFxAnouDi45prS5bm55VvqGzbAG2+U9kO0a1ca5q5umAsuaLBTA7hC2m5B13BYC9yY+nTiROnJUtdjyxbnxtIALVpASkr5lnpCAjRrFty6TVDZXCjGNFRnzjg3wCgb6hs3OmEPzkCjhITyoZ6S4gxKMk2CBbgxoaS42Jlit2IXjGswnIjT3VKxX/2884Jbt6kTFuDGhDpVZ4qAiqFe9iLszp0rh3pcXEidLDWV2UlMY0KdiBPQnTvDj8oMuTh61OlyKRvq77xTenF2bGzlQUi9ejWpQUiNlf0JGhPqYmNh+HDn4ZKfD59/Xj7Un3wSTp921p9zjjPoqOxVMElJEB0dnO/QiGVm1t2VO9aFYkxTUVTkTOxVsQsmL89ZHx7uTA9QtqXer58zx7rxS6Cunbc+cGNMZapOH3rFUHfdZBqcibwq9qt37Gj96l4I1PwxFuDGGO8dPOj0q5cdWfrf/5aub9/euQqme3fo0aP8zy5d7C5IJQI1f4ydxDTGeK9DB2ee9MsvL132/felg5A+/xx27YKPP4bFi0tnbQTn5GhcnOdw79HDuY9pE2m91/X8MRbgxhjvuG5PN3hw+eWFhbBvH+TkOKGek1P6fNmy0mvXXVq2rDrc4+OdE6yNxKxZnvvAZ80KzOdbgBtjaicy0gnfHj1gxIjK648fdzp8XeHu+vnll/Duu6XT87p07OgEuqeQ79w5pLpn6nr+GOsDN8YEj6pzd6SK4e76uW9f+c7iyEine8YV6BVDPja2UXbPWB+4MabhEXH62zt0cO5RWlFhodN0rdg1k5MD69bBkSPlt2/VqnKrvWz3TCO7zt0C3BjTcEVGwvnnOw9Pvv++crDn5DjXuy9fXjpwyaVTp6r73zt1arBT+VbFAtwYE7patXJmZkxJqbxOFb791nPXzKpV8OKL5a/xa9asfPdMxZ8N8K5KFuDGmMZJxDkh2rEjXHJJ5fVnzpTvnin7c+1a+O678tu3bl11uMfFBaV7xgLcGNM0NWvmDEa64ALP6/PyKnfP7NrlzN3+9ttQUFC6rYjTBVPVydWOHeuke8YC3BhjPGnd2pkLpl+/yuuKi53umYqt95wc+OAD536oZbtnoqLg9ddh9OiAluh3gItIV+AFoAOgwAJV/b9AFWaMMQ1WWJjT4u7UCS69tPL6ggJnCGbZcO/ZM+Bl1KYFXgT8P1VdLyItgXUi8r6qbgtQbcYYE5qiouDCC51HHfK7U0ZVv1HV9SXPjwPbgc6BKswYY0z1AtKrLiLxQCrwqYd100QkW0SycyvOiWCMMcZvtQ5wEWkBvArcqarfV1yvqgtUNV1V09u3b1/b3RljjClRqwAXkUic8M5U1dcCU5Ixxhhv+B3gIiLA34DtqjoncCUZY4zxRm1a4BnAjcAPRWRjyePKANVljDGmBn5fRqiqHwGNb95GY4wJEaE19ZYxxhg3C3BjjAlRFuDGGBOiLMCNMSZEWYAbY0yIsgA3xpgQZQFujDEhygLcGGNClAW4McaEKAtwY4wJURbgxhgToizAjTEmRFmAG2NMiLIAN8aYEFWbu9IbY0yTosWKFpU8CkufFxcWe1yuhcq7h47wzN4DfNqlkNj2Uczq0YOJHToEpB4LcGNMrah6Dq5K4VbFem+D0Ovt6/CzKfb9+LQH7gN+/RisbVXAtC++AAhIiFuAGxOCtFgpLih2Hqedhxao87zMMvfzAG138lQRp/KLCD8DEcUQUQTiR6gFRBhIhCCR4vyMEMIiw9zPyy6v+DzsnDCvt/X1s8tuP2XnDg5oEWfD4avznbLzi4u5f9cuC3Bj6puqomfUY+C5nruDr4pgrLSdH0GqhVr7LyMQFhVGWLTzkChxnpdZFt4ynMj2kYRFhbGHAj48dZr8SCiMhKIICIuAKzu0I6VNy8AFoTfbRggS1vBvCPbmyiI8/UntLSgIyOdbgJuQoOqEZqUwK/OzunXuIKywbFdePluPnKCooJiWRULP8GjanY2oNnADQaKkNCjLBGbZ5xFtIjyvqy50PWzv3qbCdhIpOPcm985Va9awx0Pu/CvqOLsvTgzIcWlsukVFscdDWHeLigrI51uANzKZBw9y/65d7C0ooFtU7U+YFBdVCEZPoejNugrb+LpOzwSgxQnOr88lAXaqmXJMimhX0qI800zZ0ewUvWKb06XLOTUGYI1h6mE7iRLCmoWFROuxoqpajYFqTTZGs3r0YNoXX5BfXPoff0xYGLN69AjI59cqwEVkNPB/QDjwrKo+GpCqygh0IDUUerbkJEmhc4Kk+Ezpcy0sv87j6zLbu9at/e57lh84xCWFytBCiCws4NPC7bRu/i09w6N9bp0WFxTD2QB82TK/qpcLuTLhFh4TTkRsROXQ8/S+qoKxunXRYZWCM37NGvYUFFUqNy6qyFqUHtR1a7IxcmVVXWWY3wEuIuHAfGAUsB9YKyL/VNVtAakMJ7zL/u+153QB07fuQPKLuf7c9lWH3BkvAtCfbX0M2uq29dgxVkttgKllXp8NgzPN4Gyzoxxp0cxjsEW0jiCsQzWhF1XDuoq/lntY5+uv6vXFWpS+qevWZGM1sUOHOmt01qYFPgD4r6ruAhCRl4GrgYAF+P27dpFfXMxtT8DVb0DEWXCS7ws+4otA7aayMJzWWqS4H2GR1b8Obx6ONPNu27Kvfd2P+3Wzyus6fLqGwgjn5FJRBBSHO19HgOJhl9Td8QpR1qL0TV23Jo3vahPgnYF9ZV7vBwZW3EhEpgHTALp16+bTDlwtoQ2pcDq69Mz32XD4Y+/zvQu8MgHpdTiGYP8kQJvzLJB8YS1K39Vla9L4rs5PYqrqAmABQHp6uk8dB64W0n8uhf9cWro8LiqKrhd3DWidjYEFkm+sRWlCXW0C/GugbIp2KVkWMBZIvrFA8p21KE0oq02ArwV6ikh3nOC+AfhpQKoqYYHkOwskY5oOvwNcVYtE5DbgXZzLCJ9T1a0Bq6yEBZIxxnhWqz5wVX0HeCdAtRhjjPGBzQdujDEhygLcGGNClAW4McaEKAtwY4wJUaJaB5NyVLUzkVxgj59vbwccDmA5gWJ1+cbq8o3V5ZuGWhfUrrY4VW1fcWG9BnhtiEi2qqYHu46KrC7fWF2+sbp801DrgrqpzbpQjDEmRFmAG2NMiAqlAF8Q7AKqYHX5xuryjdXlm4ZaF9RBbSHTB26MMaa8UGqBG2OMKcMC3BhjQlSDCnAReU5EDonIlirWi4jME5H/ishmEUlrIHUNE5E8EdlY8nignurqKiJZIrJNRLaKyK88bFPvx8zLuur9mIlItIh8JiKbSup6yMM2USKyuOR4fSoi8Q2krskiklvmeE319Fl1VF+4iGwQkbc8rKv34+VlXUE5XiKyW0Q+L9lntof1gf33qKoN5gEMAdKALVWsvxJYjnObx0HApw2krmHAW0E4Xh2BtJLnLYEvgb7BPmZe1lXvx6zkGLQoeR4JfAoMqrDNL4GnS57fACxuIHVNBv5S33/HSvZ9F/APT39ewTheXtYVlOMF7AbaVbM+oP8eG1QLXFVXA99Vs8nVwAvq+ARoIyIdG0BdQaGq36jq+pLnx4HtOPcqLavej5mXddW7kmNwouRlZMmj4ln8q4HnS54vBUaISJ3eJNXLuoJCRLoAVwHPVrFJvR8vL+tqqAL677FBBbgXPN1IOejBUOLikl+Bl4tIQn3vvORX11Sc1ltZQT1m1dQFQThmJb92bwQOAe+rapXHS1WLgDygbQOoC+Dakl+7l4pIfd0Udi7wa6C4ivVBOV5e1AXBOV4KvCci68S5oXtFAf33GGoB3lCtx5mrIAV4Ani9PncuIi2AV4E7VfX7+tx3dWqoKyjHTFXPqmo/nHu4DhCRxPrYb028qOtNIF5Vk4H3KW311hkR+RFwSFXX1fW+fOFlXfV+vEpcqqppwBXArSIypC53FmoBXuc3UvaHqn7v+hVYnbsURYpIu/rYt4hE4oRkpqq+5mGToByzmuoK5jEr2ecxIAsYXWGV+3iJSATQGjgS7LpU9YiqFpS8fBboXw/lZABjRGQ38DLwQxF5scI2wTheNdYVpOOFqn5d8vMQsAwYUGGTgP57DLUA/ydwU8mZ3EFAnqp+E+yiROQHrn4/ERmAc1zr/B99yT7/BmxX1TlVbFbvx8ybuoJxzESkvYi0KXl+DjAK2FFhs38CN5c8vw74QEvOPgWzrgr9pGNwzivUKVX9jap2UdV4nBOUH6jqpAqb1fvx8qauYBwvEWkuIi1dz4HLgIpXrgX032Ot7okZaCLyEs7VCe1EZD8wE+eEDqr6NM79N68E/gvkA7c0kLquA6aLSBFwCrihrv8Sl8gAbgQ+L+k/BbgP6FamtmAcM2/qCsYx6wg8LyLhOP9hLFHVt0TkYSBbVf+J8x/PIhH5L86J6xvquCZv67pDRMYARSV1Ta6HujxqAMfLm7qCcbw6AMtK2iURwD9U9V8i8guom3+PNpTeGGNCVKh1oRhjjClhAW6MMSHKAtwYY0KUBbgxxoQoC3BjjAlRFuDGGBOiLMCNMSZE/X+2nnf+GPAseAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjkyMbUEuMqi"
      },
      "source": [
        "### 7. 모델 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPwYDjEHtCXm",
        "outputId": "c438af54-fef3-4f5d-ff3c-4144ca0ac560"
      },
      "source": [
        "# 전이학습 평가 전처리 (위에서 설명한 것과 동일)\n",
        "data_transforms = transforms.Compose([ \n",
        "        transforms.Resize([64,64]),  \n",
        "        transforms.RandomCrop(52),  \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
        "        ])\n",
        "\n",
        "#경로 맞춰서 변경해 주세요!\n",
        "test_dataset = ImageFolder(root='/content/drive/MyDrive/plant-leaf-dataset/plant-leaf-new-dataset/test', transform=data_transforms) \n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "\n",
        "# 모델 평가 함수\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval() #모델을 평가 모드로 설정\n",
        "    test_loss = 0 #미니 배치 별로 loss를 합산해서 저장\n",
        "    correct = 0 #정확하게 예측한 수 저장   \n",
        "    with torch.no_grad(): #해당 메서드를 이용해서 parameter 업데이트 방지\n",
        "        for data, target in test_loader:  \n",
        "            data, target = data.to(DEVICE), target.to(DEVICE) #데이터와 라벨을 불러오면서 gpu에 태움  \n",
        "            output = model(data) #데이터를 모델에 입력           \n",
        "            test_loss += torch.nn.functional.cross_entropy(output,target, reduction='sum').item() #모델의 예측값과 정답값 사이의 loss 계산\n",
        "            pred = output.max(1, keepdim=True)[1]  #모델에 입력된 데이터가 12개의 클래스에 속할 확률값 출력, 이 중 가장 높은 값의 인덱스를 예측값으로 pred에 저장\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item() #target.view_as(pred)를 이용해 target의 텐서 구조를 pred의 텐서와 같은 모양으로 재정렬 (모델 만들 때 쓰는 view와 비슷 view는 숫자 직접 지정)\n",
        "                                                                  #eq는 비교 연산자로 pred와 target.view_as(pred)의 값이 일치하면 1, 일치하지 않으면 0 반환\n",
        "   \n",
        "    test_loss /= len(test_loader.dataset) #모든 미니 배치에서 합한 loss값을 배치 수로 나누어 loss값의 평균 구함\n",
        "    test_accuracy = 100. * correct / len(test_loader.dataset) #마찬가지로 정확도의 평균도 구함\n",
        "    \n",
        "    return test_loss, test_accuracy #계산한 Test 데이터의 loss와 정확도 반환\n",
        "\n",
        "# 전이학습 모델 평가 결과\n",
        "model=torch.load('/content/drive/MyDrive/plant-leaf-dataset/vgg16.pt') #torch.load를 이용해서 원하는 모델 불러오기!\n",
        "test_loss, test_accuracy = evaluate(model, test_loader) #평가 함수 이용해서 Test 데이터에 대한 loss 및 정확도 측정\n",
        "print('model test acc:  ', test_accuracy) #평가 정확도 출력"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model test acc:   51.724137931034484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(과제) 한 가지 이상의 변화를 준 후 학습을 돌려서 결과와 함께 간단한 설명을 업로드 해주세요 😀\n",
        "\n",
        "예시 : 다른 전이학습 모델 사용, freeze 시키는 구간 변화, 직접 짠 모델과의 성능 비교, 데이터 수의 변화, optimizer에 대한 실험, epoch 늘리기, 등등"
      ],
      "metadata": {
        "id": "maEk9ITatoai"
      }
    }
  ]
}